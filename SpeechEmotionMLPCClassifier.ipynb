{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "SpeechEmotionMLPCClassifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VikriAulia/Tensorflow-Deep-Learning-Speech-Recognition/blob/master/SpeechEmotionMLPCClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apZPALcv4hFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5l1lGC5hiv",
        "colab_type": "code",
        "outputId": "121647ce-54b0-4f57-d4ff-215bd9af8aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.13.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCRQ30zH4hGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import soundfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B93uxV524hGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob, pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUVYWbKG4hGy",
        "colab_type": "code",
        "outputId": "7c5d8a46-ef4b-4435-8cbc-0157e7a20bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-BxaL5XEU8V",
        "colab_type": "code",
        "outputId": "e465477b-e1a6-443a-f0a5-3886fe497480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfClxVgREUep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/drive/My\\ Drive/Dataset/Speech/SpeechEmotion/SpeechEmotion.zip -d RawData "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT0OYLm24hHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(file_name, mfcc, chroma, mel):\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate=sound_file.samplerate\n",
        "        if chroma:\n",
        "            stft=np.abs(librosa.stft(X))\n",
        "        result=np.array([])\n",
        "        if mfcc:\n",
        "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result=np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result=np.hstack((result, mel))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm5UBpPKOvrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check sound dim\n",
        "def check_sound_dim(file_name):\n",
        "  with soundfile.SoundFile(file_name) as sound_file:\n",
        "    X = sound_file.read(dtype=\"float32\")\n",
        "    result = librosa.util.valid_audio(y=X, mono=True)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8nsWbiDIhwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#looping each file\n",
        "for file in glob.glob(\"/content/RawData/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        #print(file_name)\n",
        "        try:\n",
        "          result = check_sound_dim(file)\n",
        "        except:\n",
        "          print('Error at file: {}'.format(file_name))\n",
        "          os.remove(file)\n",
        "          print('File {} Removed'.format(file_name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F8DmwmxVpu1",
        "colab_type": "text"
      },
      "source": [
        "# Original source File error with invalid dim\n",
        "Error at file: 03-01-08-01-02-02-01.wav<br>\n",
        "Error at file: 03-01-02-01-01-02-01.wav<br>\n",
        "Error at file: 03-01-02-01-02-02-05.wav<br>\n",
        "Error at file: 03-01-06-01-01-02-20.wav<br>\n",
        "Error at file: 03-01-03-01-02-01-20.wav<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daPeZ6PK4hHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "\n",
        "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f1QDAhXJOIo",
        "colab_type": "code",
        "outputId": "73dfc1bc-8b6c-4c9e-a350-d9cee3adaeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emotions['02']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'calm'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W84nIpLm4hHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    x,y=[],[]\n",
        "    for file in glob.glob(\"/content/RawData/Actor_*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions[file_name.split(\"-\")[2]]\n",
        "        if emotion not in observed_emotions:\n",
        "            continue\n",
        "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        x.append(feature)\n",
        "        y.append(emotion)\n",
        "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9QbJIbG4hIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,x_test,y_train,y_test=load_data(test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tw5PWnu4hIZ",
        "colab_type": "code",
        "outputId": "29c154c0-4a0c-4a06-abe5-5973f9df59f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print((x_train.shape[0], x_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(611, 153)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54WyrGLUaasE",
        "colab_type": "code",
        "outputId": "445230b3-de3f-4831-e406-17c4edda9eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(y_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fearful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3R3N63n4hJC",
        "colab_type": "code",
        "outputId": "798000a7-2d2d-49d3-c032-a7a0e564e8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(f'Features extracted: {x_train.shape[1]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features extracted: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT_myy4-4hJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLk_rTU4hJo",
        "colab_type": "code",
        "outputId": "c5c4d7d2-ed24-48fd-da97-7de54f5d7292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "model.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_iter=800, momentum=0.9,\n",
              "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
              "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
              "              validation_fraction=0.1, verbose=False, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcMnaZJq4hKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssRTXvRA4hKp",
        "colab_type": "code",
        "outputId": "b648744b-7d4a-44f0-a9c6-a16c31098e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 75.16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDP04x3LhgqE",
        "colab_type": "text"
      },
      "source": [
        "#Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl-JZ_Qkikgg",
        "colab_type": "code",
        "outputId": "551c0584-be80-41fb-ddf8-9940249d613f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.49985529e+02,  5.44094633e+01, -1.20822934e+01, -1.23225632e+00,\n",
              "       -1.13698031e+01,  8.14747688e+00, -1.31380177e+01, -7.93106247e+00,\n",
              "       -1.08288295e+01, -1.10065392e+01, -1.04829713e+01,  1.02083939e-01,\n",
              "       -4.79857994e+00, -9.18205646e+00, -9.53599718e+00, -5.83952553e-01,\n",
              "       -8.73724378e+00, -2.32811106e+00, -9.60280822e+00, -6.67027613e+00,\n",
              "       -3.77128007e+00, -3.67093165e+00, -1.95300141e+00,  1.68917486e+00,\n",
              "       -5.39678510e-01,  2.67706595e+00, -2.51999891e+00, -4.03432391e-01,\n",
              "        5.24282412e-01,  2.29072513e+00,  2.83255115e-01,  3.68760570e+00,\n",
              "        2.84559536e+00,  8.03630403e-01, -9.49772996e-01,  1.53564308e+00,\n",
              "        1.00149204e+00,  1.40731855e+00, -8.10609027e-01, -7.75224985e-01,\n",
              "        6.44527765e-01,  6.44499765e-01,  6.38846139e-01,  5.93764273e-01,\n",
              "        6.49232281e-01,  7.14461158e-01,  7.50121296e-01,  7.04550031e-01,\n",
              "        6.64580243e-01,  6.57390416e-01,  6.28182094e-01,  6.40989847e-01,\n",
              "        8.42135115e-06,  1.32265863e-05,  2.70161322e-05,  5.38599724e-04,\n",
              "        1.05922845e-02,  4.48961457e-02,  1.36433698e-01,  3.88468150e-01,\n",
              "        4.49777691e-01,  3.87763981e-01,  5.21325998e-01,  3.72959767e-01,\n",
              "        1.06126509e-01,  2.29989077e-02,  1.30183356e-01,  2.64245614e-01,\n",
              "        4.29379917e-01,  3.27929568e-01,  1.15332128e-01,  1.93670822e-01,\n",
              "        5.77453892e-01,  5.55430147e-01,  4.45573476e-01,  3.63359151e-01,\n",
              "        2.05100425e-01,  1.18097238e-01,  1.69695918e-01,  7.80688467e-02,\n",
              "        1.97849316e-02,  2.37654492e-02,  1.26277189e-01,  2.86204727e-01,\n",
              "        1.92433006e-01,  1.54473690e-01,  2.19848617e-01,  1.59592977e-01,\n",
              "        3.03505889e-02,  1.88933559e-02,  3.11893716e-02,  1.03075366e-01,\n",
              "        7.52100902e-02,  1.32828885e-01,  1.84704101e-01,  3.54734137e-02,\n",
              "        2.54709810e-02,  2.21660878e-02,  2.58891490e-02,  5.69846830e-02,\n",
              "        4.85426549e-02,  1.62610811e-02,  1.08344417e-02,  2.96771323e-02,\n",
              "        2.37621198e-02,  1.58156349e-02,  1.15357604e-02,  8.30548695e-03,\n",
              "        8.07415524e-03,  3.29928512e-03,  2.84325155e-03,  6.13310954e-03,\n",
              "        8.54370265e-03,  3.43836576e-03,  8.73582129e-03,  9.42950825e-03,\n",
              "        1.10375166e-02,  8.91238292e-03,  3.06461373e-03,  1.91223724e-03,\n",
              "        1.24190168e-03,  9.97997618e-04,  1.73785538e-03,  1.51376238e-03,\n",
              "        7.34205333e-04,  1.20567249e-03,  5.59629816e-04,  6.05351492e-04,\n",
              "        7.97201442e-04,  8.45214836e-04,  8.62678556e-04,  8.01941442e-04,\n",
              "        8.37891009e-04,  9.28102964e-04,  1.10523532e-03,  1.06295881e-03,\n",
              "        1.53347743e-03,  1.07017326e-03,  1.72329390e-03,  1.58850783e-03,\n",
              "        1.33246763e-03,  1.22670301e-03,  1.10834994e-03,  8.04563602e-04,\n",
              "        5.31644226e-04,  5.16166966e-04,  6.67119427e-04,  8.61961994e-04,\n",
              "        9.90148259e-04,  7.10160045e-04,  1.06993777e-03,  1.09177358e-03,\n",
              "        1.25466916e-03,  1.83804660e-03,  1.51783750e-03,  1.36913840e-03,\n",
              "        1.71064267e-03,  1.59460271e-03,  1.16126623e-03,  6.68997416e-04,\n",
              "        2.36553453e-04,  1.99177983e-04,  2.23322545e-04,  2.06579118e-04,\n",
              "        1.74255352e-04,  1.71652521e-04,  1.84846756e-04,  1.03503043e-04,\n",
              "        8.22591792e-05,  6.00698046e-05,  4.41180098e-05,  3.69873478e-05,\n",
              "        2.97001848e-05,  2.34916645e-05,  1.52271060e-05,  1.17728237e-05,\n",
              "        6.75164743e-06,  2.80634543e-06,  2.76866402e-07,  6.31608415e-09])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R28RvdGhkZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_nor = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test_nor = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x1gx-D_h8DT",
        "colab_type": "code",
        "outputId": "0899a86e-5d55-4048-d8c1-665e42b5c557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "x_train_nor[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.92811366e-01,  9.82177362e-02, -2.18104615e-02, -2.22441867e-03,\n",
              "       -2.05243032e-02,  1.47074918e-02, -2.37162119e-02, -1.43168293e-02,\n",
              "       -1.95477598e-02, -1.98685540e-02, -1.89234308e-02,  1.84277748e-04,\n",
              "       -8.66220009e-03, -1.65750725e-02, -1.72139918e-02, -1.05412725e-03,\n",
              "       -1.57721149e-02, -4.20261079e-03, -1.73345963e-02, -1.20409094e-02,\n",
              "       -6.80776042e-03, -6.62661555e-03, -3.52547821e-03,  3.04922932e-03,\n",
              "       -9.74205556e-04,  4.83252988e-03, -4.54899889e-03, -7.28259639e-04,\n",
              "        9.46413151e-04,  4.13512325e-03,  5.11320540e-04,  6.65671488e-03,\n",
              "        5.13675228e-03,  1.45068071e-03, -1.71449134e-03,  2.77208003e-03,\n",
              "        1.80785244e-03,  2.54043385e-03, -1.46327824e-03, -1.39940441e-03,\n",
              "        1.16347514e-03,  1.16342460e-03,  1.15321890e-03,  1.07183896e-03,\n",
              "        1.17196754e-03,  1.28971604e-03,  1.35408826e-03,  1.27182488e-03,\n",
              "        1.19967305e-03,  1.18669427e-03,  1.13396860e-03,  1.15708863e-03,\n",
              "        1.52018784e-08,  2.38760922e-08,  4.87684160e-08,  9.72258177e-07,\n",
              "        1.91207584e-05,  8.10446845e-05,  2.46284527e-04,  7.01246804e-04,\n",
              "        8.11920278e-04,  6.99975667e-04,  9.41076353e-04,  6.73251706e-04,\n",
              "        1.91575229e-04,  4.15166868e-05,  2.35001665e-04,  4.77005367e-04,\n",
              "        7.75099052e-04,  5.91965034e-04,  2.08192837e-04,  3.49606640e-04,\n",
              "        1.04239613e-03,  1.00263977e-03,  8.04331001e-04,  6.55921067e-04,\n",
              "        3.70238892e-04,  2.13184300e-04,  3.06328126e-04,  1.40926687e-04,\n",
              "        3.57149487e-05,  4.29004161e-05,  2.27950413e-04,  5.16645059e-04,\n",
              "        3.47372186e-04,  2.78849583e-04,  3.96861724e-04,  2.88090709e-04,\n",
              "        5.47876408e-05,  3.41055128e-05,  5.63017769e-05,  1.86067431e-04,\n",
              "        1.35766176e-04,  2.39777267e-04,  3.33420282e-04,  6.40351545e-05,\n",
              "        4.59791724e-05,  4.00133145e-05,  4.67340321e-05,  1.02866417e-04,\n",
              "        8.76272136e-05,  2.93538381e-05,  1.95578908e-05,  5.35719444e-05,\n",
              "        4.28944061e-05,  2.85497367e-05,  2.08238825e-05,  1.49927251e-05,\n",
              "        1.45751346e-05,  5.95573446e-06,  5.13252132e-06,  1.10712383e-05,\n",
              "        1.54227423e-05,  6.20679714e-06,  1.57695470e-05,  1.70217623e-05,\n",
              "        1.99244733e-05,  1.60882689e-05,  5.53211527e-06,  3.45189239e-06,\n",
              "        2.24183008e-06,  1.80154445e-06,  3.13710541e-06,  2.73258188e-06,\n",
              "        1.32535742e-06,  2.17643062e-06,  1.01022084e-06,  1.09275574e-06,\n",
              "        1.43907541e-06,  1.52574723e-06,  1.55727202e-06,  1.44763187e-06,\n",
              "        1.51252655e-06,  1.67537348e-06,  1.99512557e-06,  1.91880973e-06,\n",
              "        2.76817068e-06,  1.93183297e-06,  3.11081962e-06,  2.86750931e-06,\n",
              "        2.40531603e-06,  2.21439407e-06,  2.00074794e-06,  1.45236528e-06,\n",
              "        9.59702397e-07,  9.31763480e-07,  1.20425668e-06,  1.55597851e-06,\n",
              "        1.78737511e-06,  1.28195185e-06,  1.93140786e-06,  1.97082498e-06,\n",
              "        2.26487742e-06,  3.31796649e-06,  2.73993813e-06,  2.47151261e-06,\n",
              "        3.08798214e-06,  2.87851154e-06,  2.09627026e-06,  1.20764675e-06,\n",
              "        4.27016611e-07,  3.59547943e-07,  4.03132718e-07,  3.72908169e-07,\n",
              "        3.14558630e-07,  3.09860104e-07,  3.33677798e-07,  1.86839458e-07,\n",
              "        1.48490903e-07,  1.08435553e-07,  7.96400255e-08,  6.67680463e-08,\n",
              "        5.36135580e-08,  4.24061912e-08,  2.74873486e-08,  2.12518195e-08,\n",
              "        1.21877976e-08,  5.06589990e-09,  4.99787896e-10,  1.14015366e-11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV0SD4dzjXjo",
        "colab_type": "text"
      },
      "source": [
        "##Changing dimension for new Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOudpHFNkYYY",
        "colab_type": "code",
        "outputId": "64010a28-a8cb-44c8-ab82-f39f9d933735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(382, 180)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy0aLNTLjWD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train =np.expand_dims(x_train_nor, axis=2)\n",
        "x_test= np.expand_dims(x_test_nor, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXLtRyp5kXuV",
        "colab_type": "code",
        "outputId": "5cc406d1-92e5-4fbe-b0ce-b4f47636b149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(x_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn6L4EzEwVeK",
        "colab_type": "text"
      },
      "source": [
        "#changing label to numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epmmLFOArwav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_new = np.array(y_train)\n",
        "y_test_new = np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK52LfpWr4P5",
        "colab_type": "code",
        "outputId": "5c6b054f-68f2-4f0c-c9e2-4668d8d8b451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(y_train_new[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.str_"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsH6Yj0wiol",
        "colab_type": "text"
      },
      "source": [
        "#Changing label to categorical dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr93YfzYr-wp",
        "colab_type": "code",
        "outputId": "fbcb2fc2-ef3e-42da-b847-afaf06129afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train_new))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test_new))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJcjh7f7s1d7",
        "colab_type": "code",
        "outputId": "cbd2aa6e-d91d-4d5d-9e9a-55156027fbd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_test[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LVSIqFocJcf",
        "colab_type": "text"
      },
      "source": [
        "# Model 2 CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTDi5dOOcMjk",
        "colab_type": "code",
        "outputId": "d690b4f1-b2b9-4fc7-e0be-79db1b122cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu',input_shape=(180, 1)),\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.MaxPool1D(pool_size=8, padding='same'),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv1D(128, 5, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001, decay=1e-6),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NULIi6DUjxg-",
        "colab_type": "code",
        "outputId": "27975ff9-d75c-42cb-d085-93a47f03700a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 180, 128)          768       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 180, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 23, 128)           82048     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 23, 128)           82048     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 23, 128)           82048     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2944)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               376960    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 132       \n",
            "=================================================================\n",
            "Total params: 634,340\n",
            "Trainable params: 634,340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3gkhEFUjN_u",
        "colab_type": "code",
        "outputId": "b20d4755-5355-4088-a9b5-a1f8c02dea00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model2.fit(x_train,y_train, batch_size=16, epochs=1000, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 611 samples, validate on 153 samples\n",
            "Epoch 1/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.3292 - acc: 0.3241 - val_loss: 1.3322 - val_acc: 0.3007\n",
            "Epoch 2/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.3277 - acc: 0.3257 - val_loss: 1.3237 - val_acc: 0.2876\n",
            "Epoch 3/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.3334 - acc: 0.3273 - val_loss: 1.3224 - val_acc: 0.2810\n",
            "Epoch 4/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.3291 - acc: 0.3421 - val_loss: 1.3199 - val_acc: 0.2941\n",
            "Epoch 5/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.3260 - acc: 0.3421 - val_loss: 1.3180 - val_acc: 0.3007\n",
            "Epoch 6/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.3266 - acc: 0.3191 - val_loss: 1.3201 - val_acc: 0.2745\n",
            "Epoch 7/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.3281 - acc: 0.3159 - val_loss: 1.3177 - val_acc: 0.2745\n",
            "Epoch 8/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.3215 - acc: 0.3388 - val_loss: 1.3129 - val_acc: 0.2941\n",
            "Epoch 9/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.3223 - acc: 0.3224 - val_loss: 1.3108 - val_acc: 0.3007\n",
            "Epoch 10/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.3163 - acc: 0.3241 - val_loss: 1.3103 - val_acc: 0.3072\n",
            "Epoch 11/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.3115 - acc: 0.3486 - val_loss: 1.3063 - val_acc: 0.2941\n",
            "Epoch 12/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.3127 - acc: 0.3404 - val_loss: 1.3106 - val_acc: 0.2941\n",
            "Epoch 13/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.3143 - acc: 0.3355 - val_loss: 1.3029 - val_acc: 0.3007\n",
            "Epoch 14/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.3198 - acc: 0.3093 - val_loss: 1.3009 - val_acc: 0.3007\n",
            "Epoch 15/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.3070 - acc: 0.3372 - val_loss: 1.2995 - val_acc: 0.3007\n",
            "Epoch 16/1000\n",
            "611/611 [==============================] - 0s 381us/sample - loss: 1.3038 - acc: 0.3257 - val_loss: 1.3003 - val_acc: 0.3007\n",
            "Epoch 17/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.3045 - acc: 0.3437 - val_loss: 1.2960 - val_acc: 0.3007\n",
            "Epoch 18/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.3016 - acc: 0.3519 - val_loss: 1.2935 - val_acc: 0.3072\n",
            "Epoch 19/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2992 - acc: 0.3372 - val_loss: 1.2912 - val_acc: 0.3072\n",
            "Epoch 20/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.2995 - acc: 0.3502 - val_loss: 1.3084 - val_acc: 0.2810\n",
            "Epoch 21/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2985 - acc: 0.3257 - val_loss: 1.2913 - val_acc: 0.2941\n",
            "Epoch 22/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.2965 - acc: 0.3486 - val_loss: 1.2846 - val_acc: 0.3072\n",
            "Epoch 23/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.2909 - acc: 0.3502 - val_loss: 1.2873 - val_acc: 0.2941\n",
            "Epoch 24/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.2909 - acc: 0.3421 - val_loss: 1.2809 - val_acc: 0.3072\n",
            "Epoch 25/1000\n",
            "611/611 [==============================] - 0s 371us/sample - loss: 1.2901 - acc: 0.3421 - val_loss: 1.2835 - val_acc: 0.2941\n",
            "Epoch 26/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.2917 - acc: 0.3519 - val_loss: 1.2768 - val_acc: 0.3007\n",
            "Epoch 27/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.2859 - acc: 0.3437 - val_loss: 1.2797 - val_acc: 0.2941\n",
            "Epoch 28/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2893 - acc: 0.3159 - val_loss: 1.2744 - val_acc: 0.3007\n",
            "Epoch 29/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2876 - acc: 0.3404 - val_loss: 1.2799 - val_acc: 0.2810\n",
            "Epoch 30/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.2810 - acc: 0.3699 - val_loss: 1.2707 - val_acc: 0.3072\n",
            "Epoch 31/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.2833 - acc: 0.3486 - val_loss: 1.2693 - val_acc: 0.3660\n",
            "Epoch 32/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2768 - acc: 0.3404 - val_loss: 1.2663 - val_acc: 0.3791\n",
            "Epoch 33/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2862 - acc: 0.3404 - val_loss: 1.2655 - val_acc: 0.3791\n",
            "Epoch 34/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.2833 - acc: 0.3175 - val_loss: 1.2705 - val_acc: 0.3660\n",
            "Epoch 35/1000\n",
            "611/611 [==============================] - 0s 382us/sample - loss: 1.2865 - acc: 0.3388 - val_loss: 1.2720 - val_acc: 0.3464\n",
            "Epoch 36/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.2807 - acc: 0.3404 - val_loss: 1.2599 - val_acc: 0.3922\n",
            "Epoch 37/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.2817 - acc: 0.3453 - val_loss: 1.2702 - val_acc: 0.3399\n",
            "Epoch 38/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2675 - acc: 0.3633 - val_loss: 1.2771 - val_acc: 0.3333\n",
            "Epoch 39/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2830 - acc: 0.3191 - val_loss: 1.2562 - val_acc: 0.3595\n",
            "Epoch 40/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.2755 - acc: 0.3421 - val_loss: 1.2654 - val_acc: 0.3856\n",
            "Epoch 41/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.2612 - acc: 0.3601 - val_loss: 1.2566 - val_acc: 0.3791\n",
            "Epoch 42/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.2574 - acc: 0.3797 - val_loss: 1.2518 - val_acc: 0.3725\n",
            "Epoch 43/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.2598 - acc: 0.3584 - val_loss: 1.2512 - val_acc: 0.3660\n",
            "Epoch 44/1000\n",
            "611/611 [==============================] - 0s 391us/sample - loss: 1.2620 - acc: 0.3764 - val_loss: 1.2472 - val_acc: 0.3791\n",
            "Epoch 45/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.2639 - acc: 0.3650 - val_loss: 1.2465 - val_acc: 0.3791\n",
            "Epoch 46/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2618 - acc: 0.3830 - val_loss: 1.2463 - val_acc: 0.3725\n",
            "Epoch 47/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.2708 - acc: 0.3437 - val_loss: 1.2443 - val_acc: 0.3987\n",
            "Epoch 48/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2648 - acc: 0.3617 - val_loss: 1.2461 - val_acc: 0.3987\n",
            "Epoch 49/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.2604 - acc: 0.3846 - val_loss: 1.2459 - val_acc: 0.3922\n",
            "Epoch 50/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2624 - acc: 0.3863 - val_loss: 1.2407 - val_acc: 0.3856\n",
            "Epoch 51/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.2562 - acc: 0.3699 - val_loss: 1.2547 - val_acc: 0.3856\n",
            "Epoch 52/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.2647 - acc: 0.3666 - val_loss: 1.2389 - val_acc: 0.3922\n",
            "Epoch 53/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.2468 - acc: 0.3453 - val_loss: 1.2502 - val_acc: 0.3725\n",
            "Epoch 54/1000\n",
            "611/611 [==============================] - 0s 434us/sample - loss: 1.2609 - acc: 0.3797 - val_loss: 1.2382 - val_acc: 0.4052\n",
            "Epoch 55/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.2506 - acc: 0.3633 - val_loss: 1.2386 - val_acc: 0.4052\n",
            "Epoch 56/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.2608 - acc: 0.3912 - val_loss: 1.2346 - val_acc: 0.3987\n",
            "Epoch 57/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2475 - acc: 0.3715 - val_loss: 1.2349 - val_acc: 0.3987\n",
            "Epoch 58/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.2494 - acc: 0.3617 - val_loss: 1.2491 - val_acc: 0.3725\n",
            "Epoch 59/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2432 - acc: 0.3633 - val_loss: 1.2317 - val_acc: 0.3987\n",
            "Epoch 60/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.2565 - acc: 0.3682 - val_loss: 1.2308 - val_acc: 0.3922\n",
            "Epoch 61/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.2559 - acc: 0.3699 - val_loss: 1.2308 - val_acc: 0.3987\n",
            "Epoch 62/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.2455 - acc: 0.3764 - val_loss: 1.2441 - val_acc: 0.3987\n",
            "Epoch 63/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.2497 - acc: 0.3633 - val_loss: 1.2363 - val_acc: 0.4118\n",
            "Epoch 64/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.2488 - acc: 0.3993 - val_loss: 1.2270 - val_acc: 0.3922\n",
            "Epoch 65/1000\n",
            "611/611 [==============================] - 0s 436us/sample - loss: 1.2469 - acc: 0.3944 - val_loss: 1.2333 - val_acc: 0.4118\n",
            "Epoch 66/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2451 - acc: 0.3699 - val_loss: 1.2294 - val_acc: 0.3922\n",
            "Epoch 67/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2454 - acc: 0.3732 - val_loss: 1.2606 - val_acc: 0.3660\n",
            "Epoch 68/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.2517 - acc: 0.3732 - val_loss: 1.2247 - val_acc: 0.4183\n",
            "Epoch 69/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2508 - acc: 0.3895 - val_loss: 1.2238 - val_acc: 0.4052\n",
            "Epoch 70/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.2453 - acc: 0.4223 - val_loss: 1.2233 - val_acc: 0.4118\n",
            "Epoch 71/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.2429 - acc: 0.3977 - val_loss: 1.2290 - val_acc: 0.4052\n",
            "Epoch 72/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2446 - acc: 0.3813 - val_loss: 1.2268 - val_acc: 0.4248\n",
            "Epoch 73/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.2575 - acc: 0.3715 - val_loss: 1.2215 - val_acc: 0.4118\n",
            "Epoch 74/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2476 - acc: 0.4059 - val_loss: 1.2429 - val_acc: 0.3922\n",
            "Epoch 75/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2648 - acc: 0.3453 - val_loss: 1.2218 - val_acc: 0.4052\n",
            "Epoch 76/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.2481 - acc: 0.3781 - val_loss: 1.2215 - val_acc: 0.4118\n",
            "Epoch 77/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2339 - acc: 0.3781 - val_loss: 1.2199 - val_acc: 0.4183\n",
            "Epoch 78/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.2448 - acc: 0.3863 - val_loss: 1.2302 - val_acc: 0.4118\n",
            "Epoch 79/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2471 - acc: 0.3682 - val_loss: 1.2233 - val_acc: 0.4379\n",
            "Epoch 80/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.2320 - acc: 0.3813 - val_loss: 1.2175 - val_acc: 0.4379\n",
            "Epoch 81/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.2384 - acc: 0.4223 - val_loss: 1.2286 - val_acc: 0.4118\n",
            "Epoch 82/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2383 - acc: 0.3699 - val_loss: 1.2250 - val_acc: 0.4248\n",
            "Epoch 83/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.2375 - acc: 0.3666 - val_loss: 1.2158 - val_acc: 0.4248\n",
            "Epoch 84/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2392 - acc: 0.3732 - val_loss: 1.2234 - val_acc: 0.4444\n",
            "Epoch 85/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.2462 - acc: 0.3846 - val_loss: 1.2163 - val_acc: 0.4248\n",
            "Epoch 86/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.2360 - acc: 0.3944 - val_loss: 1.2182 - val_acc: 0.4379\n",
            "Epoch 87/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.2422 - acc: 0.3830 - val_loss: 1.2355 - val_acc: 0.4575\n",
            "Epoch 88/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.2449 - acc: 0.3764 - val_loss: 1.2149 - val_acc: 0.4314\n",
            "Epoch 89/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2424 - acc: 0.3682 - val_loss: 1.2136 - val_acc: 0.4379\n",
            "Epoch 90/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2467 - acc: 0.3650 - val_loss: 1.2280 - val_acc: 0.4314\n",
            "Epoch 91/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.2394 - acc: 0.3764 - val_loss: 1.2289 - val_acc: 0.4248\n",
            "Epoch 92/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2359 - acc: 0.4059 - val_loss: 1.2296 - val_acc: 0.4379\n",
            "Epoch 93/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.2472 - acc: 0.3830 - val_loss: 1.2204 - val_acc: 0.4379\n",
            "Epoch 94/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.2412 - acc: 0.3993 - val_loss: 1.2173 - val_acc: 0.4248\n",
            "Epoch 95/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.2346 - acc: 0.3764 - val_loss: 1.2109 - val_acc: 0.4314\n",
            "Epoch 96/1000\n",
            "611/611 [==============================] - 0s 388us/sample - loss: 1.2438 - acc: 0.3830 - val_loss: 1.2130 - val_acc: 0.4379\n",
            "Epoch 97/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.2337 - acc: 0.4010 - val_loss: 1.2144 - val_acc: 0.4444\n",
            "Epoch 98/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.2555 - acc: 0.3699 - val_loss: 1.2146 - val_acc: 0.4379\n",
            "Epoch 99/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2361 - acc: 0.3863 - val_loss: 1.2102 - val_acc: 0.4314\n",
            "Epoch 100/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.2364 - acc: 0.3748 - val_loss: 1.2165 - val_acc: 0.4314\n",
            "Epoch 101/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.2388 - acc: 0.3781 - val_loss: 1.2186 - val_acc: 0.4444\n",
            "Epoch 102/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.2335 - acc: 0.3928 - val_loss: 1.2186 - val_acc: 0.4444\n",
            "Epoch 103/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2344 - acc: 0.3863 - val_loss: 1.2094 - val_acc: 0.4183\n",
            "Epoch 104/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2314 - acc: 0.4026 - val_loss: 1.2085 - val_acc: 0.4118\n",
            "Epoch 105/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.2354 - acc: 0.3928 - val_loss: 1.2069 - val_acc: 0.4314\n",
            "Epoch 106/1000\n",
            "611/611 [==============================] - 0s 381us/sample - loss: 1.2392 - acc: 0.3961 - val_loss: 1.2333 - val_acc: 0.4510\n",
            "Epoch 107/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.2415 - acc: 0.3748 - val_loss: 1.2118 - val_acc: 0.4444\n",
            "Epoch 108/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2262 - acc: 0.4059 - val_loss: 1.2051 - val_acc: 0.4510\n",
            "Epoch 109/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2252 - acc: 0.4026 - val_loss: 1.2120 - val_acc: 0.4641\n",
            "Epoch 110/1000\n",
            "611/611 [==============================] - 0s 379us/sample - loss: 1.2354 - acc: 0.4190 - val_loss: 1.2174 - val_acc: 0.4706\n",
            "Epoch 111/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2426 - acc: 0.4108 - val_loss: 1.2050 - val_acc: 0.4706\n",
            "Epoch 112/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.2276 - acc: 0.4075 - val_loss: 1.2042 - val_acc: 0.4575\n",
            "Epoch 113/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2147 - acc: 0.3961 - val_loss: 1.2035 - val_acc: 0.4641\n",
            "Epoch 114/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2337 - acc: 0.3813 - val_loss: 1.2131 - val_acc: 0.4771\n",
            "Epoch 115/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.2370 - acc: 0.4043 - val_loss: 1.2148 - val_acc: 0.4510\n",
            "Epoch 116/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.2282 - acc: 0.3928 - val_loss: 1.2029 - val_acc: 0.4771\n",
            "Epoch 117/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2318 - acc: 0.3863 - val_loss: 1.2081 - val_acc: 0.4510\n",
            "Epoch 118/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2313 - acc: 0.3928 - val_loss: 1.2046 - val_acc: 0.4379\n",
            "Epoch 119/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.2327 - acc: 0.3928 - val_loss: 1.2020 - val_acc: 0.4575\n",
            "Epoch 120/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.2239 - acc: 0.3912 - val_loss: 1.2204 - val_acc: 0.4706\n",
            "Epoch 121/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.2196 - acc: 0.3863 - val_loss: 1.2009 - val_acc: 0.4641\n",
            "Epoch 122/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.2308 - acc: 0.4059 - val_loss: 1.2123 - val_acc: 0.4444\n",
            "Epoch 123/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2249 - acc: 0.4010 - val_loss: 1.2016 - val_acc: 0.4444\n",
            "Epoch 124/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.2343 - acc: 0.4141 - val_loss: 1.2075 - val_acc: 0.4510\n",
            "Epoch 125/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2183 - acc: 0.4141 - val_loss: 1.2000 - val_acc: 0.4575\n",
            "Epoch 126/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.2267 - acc: 0.3715 - val_loss: 1.2006 - val_acc: 0.4444\n",
            "Epoch 127/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.2355 - acc: 0.3846 - val_loss: 1.2120 - val_acc: 0.4575\n",
            "Epoch 128/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2267 - acc: 0.3928 - val_loss: 1.2119 - val_acc: 0.4706\n",
            "Epoch 129/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.2307 - acc: 0.3961 - val_loss: 1.2041 - val_acc: 0.4641\n",
            "Epoch 130/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.2235 - acc: 0.3830 - val_loss: 1.2043 - val_acc: 0.4706\n",
            "Epoch 131/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2119 - acc: 0.4124 - val_loss: 1.2039 - val_acc: 0.4510\n",
            "Epoch 132/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.2261 - acc: 0.3993 - val_loss: 1.2035 - val_acc: 0.4706\n",
            "Epoch 133/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.2254 - acc: 0.4059 - val_loss: 1.2216 - val_acc: 0.4314\n",
            "Epoch 134/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2315 - acc: 0.4043 - val_loss: 1.2060 - val_acc: 0.4771\n",
            "Epoch 135/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.2186 - acc: 0.4075 - val_loss: 1.2119 - val_acc: 0.4575\n",
            "Epoch 136/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.2193 - acc: 0.4026 - val_loss: 1.2022 - val_acc: 0.4641\n",
            "Epoch 137/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.2265 - acc: 0.3993 - val_loss: 1.1984 - val_acc: 0.4641\n",
            "Epoch 138/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.2250 - acc: 0.3895 - val_loss: 1.2044 - val_acc: 0.4641\n",
            "Epoch 139/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2160 - acc: 0.4173 - val_loss: 1.2057 - val_acc: 0.4771\n",
            "Epoch 140/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2255 - acc: 0.4108 - val_loss: 1.2000 - val_acc: 0.4641\n",
            "Epoch 141/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.2305 - acc: 0.3813 - val_loss: 1.1976 - val_acc: 0.4706\n",
            "Epoch 142/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2162 - acc: 0.4059 - val_loss: 1.2099 - val_acc: 0.4641\n",
            "Epoch 143/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.2136 - acc: 0.3830 - val_loss: 1.2094 - val_acc: 0.4837\n",
            "Epoch 144/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2155 - acc: 0.4272 - val_loss: 1.1958 - val_acc: 0.4706\n",
            "Epoch 145/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.2176 - acc: 0.4059 - val_loss: 1.2191 - val_acc: 0.4575\n",
            "Epoch 146/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.2233 - acc: 0.3895 - val_loss: 1.2039 - val_acc: 0.4510\n",
            "Epoch 147/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2226 - acc: 0.4043 - val_loss: 1.1950 - val_acc: 0.4510\n",
            "Epoch 148/1000\n",
            "611/611 [==============================] - 0s 363us/sample - loss: 1.2237 - acc: 0.4026 - val_loss: 1.2071 - val_acc: 0.4902\n",
            "Epoch 149/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2182 - acc: 0.3928 - val_loss: 1.2063 - val_acc: 0.4837\n",
            "Epoch 150/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.2269 - acc: 0.4043 - val_loss: 1.2106 - val_acc: 0.4837\n",
            "Epoch 151/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.2220 - acc: 0.4059 - val_loss: 1.2025 - val_acc: 0.4837\n",
            "Epoch 152/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2001 - acc: 0.4108 - val_loss: 1.1963 - val_acc: 0.4706\n",
            "Epoch 153/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2243 - acc: 0.4173 - val_loss: 1.1964 - val_acc: 0.3922\n",
            "Epoch 154/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2155 - acc: 0.3928 - val_loss: 1.1931 - val_acc: 0.4314\n",
            "Epoch 155/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.2146 - acc: 0.4337 - val_loss: 1.2181 - val_acc: 0.4444\n",
            "Epoch 156/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.2208 - acc: 0.4272 - val_loss: 1.1968 - val_acc: 0.4771\n",
            "Epoch 157/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.2106 - acc: 0.4173 - val_loss: 1.1925 - val_acc: 0.4052\n",
            "Epoch 158/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.2104 - acc: 0.4272 - val_loss: 1.1968 - val_acc: 0.4706\n",
            "Epoch 159/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2350 - acc: 0.3813 - val_loss: 1.1913 - val_acc: 0.4771\n",
            "Epoch 160/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2104 - acc: 0.4010 - val_loss: 1.1963 - val_acc: 0.4837\n",
            "Epoch 161/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.2192 - acc: 0.4010 - val_loss: 1.2055 - val_acc: 0.4706\n",
            "Epoch 162/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2238 - acc: 0.4141 - val_loss: 1.2036 - val_acc: 0.4837\n",
            "Epoch 163/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 1.1989 - acc: 0.4223 - val_loss: 1.1903 - val_acc: 0.4248\n",
            "Epoch 164/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2177 - acc: 0.4010 - val_loss: 1.1931 - val_acc: 0.4510\n",
            "Epoch 165/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.2184 - acc: 0.4092 - val_loss: 1.1919 - val_acc: 0.4314\n",
            "Epoch 166/1000\n",
            "611/611 [==============================] - 0s 371us/sample - loss: 1.2322 - acc: 0.4190 - val_loss: 1.1912 - val_acc: 0.4052\n",
            "Epoch 167/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.2071 - acc: 0.4255 - val_loss: 1.2065 - val_acc: 0.4902\n",
            "Epoch 168/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2167 - acc: 0.3961 - val_loss: 1.1912 - val_acc: 0.4379\n",
            "Epoch 169/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.2170 - acc: 0.3830 - val_loss: 1.1958 - val_acc: 0.4183\n",
            "Epoch 170/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.2196 - acc: 0.4026 - val_loss: 1.2295 - val_acc: 0.4314\n",
            "Epoch 171/1000\n",
            "611/611 [==============================] - 0s 381us/sample - loss: 1.2270 - acc: 0.4043 - val_loss: 1.1916 - val_acc: 0.4052\n",
            "Epoch 172/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2104 - acc: 0.4239 - val_loss: 1.1880 - val_acc: 0.4248\n",
            "Epoch 173/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.2092 - acc: 0.4075 - val_loss: 1.1973 - val_acc: 0.4837\n",
            "Epoch 174/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2179 - acc: 0.3912 - val_loss: 1.1884 - val_acc: 0.4183\n",
            "Epoch 175/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.1998 - acc: 0.4157 - val_loss: 1.2157 - val_acc: 0.4575\n",
            "Epoch 176/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.2204 - acc: 0.4206 - val_loss: 1.1994 - val_acc: 0.4902\n",
            "Epoch 177/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2230 - acc: 0.3977 - val_loss: 1.1905 - val_acc: 0.4771\n",
            "Epoch 178/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2209 - acc: 0.4043 - val_loss: 1.2131 - val_acc: 0.4510\n",
            "Epoch 179/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.2147 - acc: 0.3961 - val_loss: 1.1876 - val_acc: 0.4118\n",
            "Epoch 180/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.2161 - acc: 0.3781 - val_loss: 1.2037 - val_acc: 0.4444\n",
            "Epoch 181/1000\n",
            "611/611 [==============================] - 0s 367us/sample - loss: 1.2002 - acc: 0.4403 - val_loss: 1.1871 - val_acc: 0.4118\n",
            "Epoch 182/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.2162 - acc: 0.4173 - val_loss: 1.1871 - val_acc: 0.4052\n",
            "Epoch 183/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2126 - acc: 0.4043 - val_loss: 1.1952 - val_acc: 0.4837\n",
            "Epoch 184/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.2137 - acc: 0.4108 - val_loss: 1.1876 - val_acc: 0.4052\n",
            "Epoch 185/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.1935 - acc: 0.4124 - val_loss: 1.1874 - val_acc: 0.4771\n",
            "Epoch 186/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.2058 - acc: 0.4043 - val_loss: 1.1844 - val_acc: 0.4314\n",
            "Epoch 187/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.2100 - acc: 0.4223 - val_loss: 1.1940 - val_acc: 0.4771\n",
            "Epoch 188/1000\n",
            "611/611 [==============================] - 0s 310us/sample - loss: 1.2083 - acc: 0.4026 - val_loss: 1.2016 - val_acc: 0.4837\n",
            "Epoch 189/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.2067 - acc: 0.3993 - val_loss: 1.1847 - val_acc: 0.4379\n",
            "Epoch 190/1000\n",
            "611/611 [==============================] - 0s 393us/sample - loss: 1.2198 - acc: 0.4223 - val_loss: 1.1917 - val_acc: 0.4771\n",
            "Epoch 191/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.2012 - acc: 0.4124 - val_loss: 1.1853 - val_acc: 0.4641\n",
            "Epoch 192/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2095 - acc: 0.4223 - val_loss: 1.2127 - val_acc: 0.4314\n",
            "Epoch 193/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.2155 - acc: 0.4092 - val_loss: 1.1866 - val_acc: 0.4052\n",
            "Epoch 194/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.2112 - acc: 0.4108 - val_loss: 1.1836 - val_acc: 0.4183\n",
            "Epoch 195/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.2080 - acc: 0.4272 - val_loss: 1.1838 - val_acc: 0.4183\n",
            "Epoch 196/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2096 - acc: 0.3912 - val_loss: 1.2142 - val_acc: 0.4706\n",
            "Epoch 197/1000\n",
            "611/611 [==============================] - 0s 389us/sample - loss: 1.2122 - acc: 0.4108 - val_loss: 1.1838 - val_acc: 0.4183\n",
            "Epoch 198/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2054 - acc: 0.4157 - val_loss: 1.1827 - val_acc: 0.4183\n",
            "Epoch 199/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.2095 - acc: 0.4337 - val_loss: 1.1828 - val_acc: 0.4183\n",
            "Epoch 200/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.2035 - acc: 0.4255 - val_loss: 1.1848 - val_acc: 0.4379\n",
            "Epoch 201/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.2261 - acc: 0.3748 - val_loss: 1.1856 - val_acc: 0.4052\n",
            "Epoch 202/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.2115 - acc: 0.3863 - val_loss: 1.1982 - val_acc: 0.4967\n",
            "Epoch 203/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.2044 - acc: 0.4075 - val_loss: 1.1821 - val_acc: 0.4183\n",
            "Epoch 204/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2153 - acc: 0.4157 - val_loss: 1.1894 - val_acc: 0.4510\n",
            "Epoch 205/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.2024 - acc: 0.4386 - val_loss: 1.1915 - val_acc: 0.4248\n",
            "Epoch 206/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.2075 - acc: 0.3961 - val_loss: 1.2076 - val_acc: 0.4967\n",
            "Epoch 207/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.2067 - acc: 0.4124 - val_loss: 1.1929 - val_acc: 0.4837\n",
            "Epoch 208/1000\n",
            "611/611 [==============================] - 0s 387us/sample - loss: 1.2146 - acc: 0.3993 - val_loss: 1.1795 - val_acc: 0.4379\n",
            "Epoch 209/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.2095 - acc: 0.3961 - val_loss: 1.1787 - val_acc: 0.4183\n",
            "Epoch 210/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.1992 - acc: 0.4288 - val_loss: 1.1791 - val_acc: 0.4248\n",
            "Epoch 211/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.1984 - acc: 0.4173 - val_loss: 1.1805 - val_acc: 0.4771\n",
            "Epoch 212/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.2034 - acc: 0.4173 - val_loss: 1.1884 - val_acc: 0.4837\n",
            "Epoch 213/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.2092 - acc: 0.4010 - val_loss: 1.1793 - val_acc: 0.4510\n",
            "Epoch 214/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.2088 - acc: 0.4239 - val_loss: 1.1903 - val_acc: 0.4837\n",
            "Epoch 215/1000\n",
            "611/611 [==============================] - 0s 381us/sample - loss: 1.2122 - acc: 0.4452 - val_loss: 1.1778 - val_acc: 0.4183\n",
            "Epoch 216/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.2116 - acc: 0.4255 - val_loss: 1.2222 - val_acc: 0.3987\n",
            "Epoch 217/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.2090 - acc: 0.4026 - val_loss: 1.1906 - val_acc: 0.4837\n",
            "Epoch 218/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.1889 - acc: 0.4255 - val_loss: 1.1825 - val_acc: 0.4641\n",
            "Epoch 219/1000\n",
            "611/611 [==============================] - 0s 378us/sample - loss: 1.2110 - acc: 0.4190 - val_loss: 1.1780 - val_acc: 0.4183\n",
            "Epoch 220/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.2012 - acc: 0.4386 - val_loss: 1.1843 - val_acc: 0.4510\n",
            "Epoch 221/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1886 - acc: 0.4484 - val_loss: 1.1746 - val_acc: 0.4183\n",
            "Epoch 222/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1925 - acc: 0.4386 - val_loss: 1.1948 - val_acc: 0.4771\n",
            "Epoch 223/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1983 - acc: 0.4075 - val_loss: 1.1848 - val_acc: 0.4837\n",
            "Epoch 224/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1956 - acc: 0.4501 - val_loss: 1.1758 - val_acc: 0.4444\n",
            "Epoch 225/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.2102 - acc: 0.4108 - val_loss: 1.1763 - val_acc: 0.4118\n",
            "Epoch 226/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1872 - acc: 0.4452 - val_loss: 1.1716 - val_acc: 0.4183\n",
            "Epoch 227/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.1924 - acc: 0.4501 - val_loss: 1.1815 - val_acc: 0.4837\n",
            "Epoch 228/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2071 - acc: 0.3993 - val_loss: 1.1724 - val_acc: 0.4314\n",
            "Epoch 229/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1968 - acc: 0.4157 - val_loss: 1.1793 - val_acc: 0.4052\n",
            "Epoch 230/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1888 - acc: 0.4386 - val_loss: 1.2109 - val_acc: 0.4641\n",
            "Epoch 231/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.1970 - acc: 0.4157 - val_loss: 1.1785 - val_acc: 0.4771\n",
            "Epoch 232/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.2069 - acc: 0.4190 - val_loss: 1.1840 - val_acc: 0.4052\n",
            "Epoch 233/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.2052 - acc: 0.4255 - val_loss: 1.1781 - val_acc: 0.4118\n",
            "Epoch 234/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.2069 - acc: 0.3912 - val_loss: 1.1756 - val_acc: 0.4444\n",
            "Epoch 235/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.2032 - acc: 0.4239 - val_loss: 1.2024 - val_acc: 0.4902\n",
            "Epoch 236/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1971 - acc: 0.4239 - val_loss: 1.1713 - val_acc: 0.4248\n",
            "Epoch 237/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.2020 - acc: 0.4124 - val_loss: 1.1848 - val_acc: 0.4837\n",
            "Epoch 238/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1920 - acc: 0.4468 - val_loss: 1.1690 - val_acc: 0.4314\n",
            "Epoch 239/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1911 - acc: 0.3961 - val_loss: 1.1679 - val_acc: 0.4379\n",
            "Epoch 240/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.1977 - acc: 0.4141 - val_loss: 1.1733 - val_acc: 0.4379\n",
            "Epoch 241/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1754 - acc: 0.4370 - val_loss: 1.2198 - val_acc: 0.4902\n",
            "Epoch 242/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1933 - acc: 0.4206 - val_loss: 1.1728 - val_acc: 0.4641\n",
            "Epoch 243/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.1922 - acc: 0.4223 - val_loss: 1.1713 - val_acc: 0.4641\n",
            "Epoch 244/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1744 - acc: 0.4354 - val_loss: 1.1650 - val_acc: 0.4444\n",
            "Epoch 245/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1895 - acc: 0.4239 - val_loss: 1.1835 - val_acc: 0.4902\n",
            "Epoch 246/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1765 - acc: 0.4435 - val_loss: 1.1708 - val_acc: 0.4771\n",
            "Epoch 247/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.2037 - acc: 0.4386 - val_loss: 1.1645 - val_acc: 0.4444\n",
            "Epoch 248/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1827 - acc: 0.4386 - val_loss: 1.1673 - val_acc: 0.4641\n",
            "Epoch 249/1000\n",
            "611/611 [==============================] - 0s 366us/sample - loss: 1.1861 - acc: 0.4092 - val_loss: 1.1652 - val_acc: 0.4248\n",
            "Epoch 250/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1967 - acc: 0.4173 - val_loss: 1.2062 - val_acc: 0.3987\n",
            "Epoch 251/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.1977 - acc: 0.4386 - val_loss: 1.1879 - val_acc: 0.4183\n",
            "Epoch 252/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.1806 - acc: 0.4435 - val_loss: 1.1927 - val_acc: 0.4902\n",
            "Epoch 253/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1941 - acc: 0.4157 - val_loss: 1.1687 - val_acc: 0.4183\n",
            "Epoch 254/1000\n",
            "611/611 [==============================] - 0s 363us/sample - loss: 1.1957 - acc: 0.4255 - val_loss: 1.1759 - val_acc: 0.4837\n",
            "Epoch 255/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1907 - acc: 0.4337 - val_loss: 1.1704 - val_acc: 0.4118\n",
            "Epoch 256/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.2012 - acc: 0.4206 - val_loss: 1.1673 - val_acc: 0.4706\n",
            "Epoch 257/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.1919 - acc: 0.4206 - val_loss: 1.1708 - val_acc: 0.4641\n",
            "Epoch 258/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.1850 - acc: 0.3928 - val_loss: 1.1753 - val_acc: 0.4837\n",
            "Epoch 259/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.1726 - acc: 0.4403 - val_loss: 1.1805 - val_acc: 0.4837\n",
            "Epoch 260/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.1903 - acc: 0.4206 - val_loss: 1.1623 - val_acc: 0.4248\n",
            "Epoch 261/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.1789 - acc: 0.4206 - val_loss: 1.1622 - val_acc: 0.4510\n",
            "Epoch 262/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1918 - acc: 0.4026 - val_loss: 1.1601 - val_acc: 0.4248\n",
            "Epoch 263/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.2033 - acc: 0.3830 - val_loss: 1.1686 - val_acc: 0.4837\n",
            "Epoch 264/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.1851 - acc: 0.4157 - val_loss: 1.1596 - val_acc: 0.4248\n",
            "Epoch 265/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1820 - acc: 0.4354 - val_loss: 1.2097 - val_acc: 0.4837\n",
            "Epoch 266/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1968 - acc: 0.4124 - val_loss: 1.1596 - val_acc: 0.4379\n",
            "Epoch 267/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1746 - acc: 0.4403 - val_loss: 1.1831 - val_acc: 0.5033\n",
            "Epoch 268/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.1967 - acc: 0.4223 - val_loss: 1.1682 - val_acc: 0.4706\n",
            "Epoch 269/1000\n",
            "611/611 [==============================] - 0s 369us/sample - loss: 1.1761 - acc: 0.4223 - val_loss: 1.1653 - val_acc: 0.4379\n",
            "Epoch 270/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1836 - acc: 0.4190 - val_loss: 1.1868 - val_acc: 0.4902\n",
            "Epoch 271/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1928 - acc: 0.4190 - val_loss: 1.1661 - val_acc: 0.4183\n",
            "Epoch 272/1000\n",
            "611/611 [==============================] - 0s 400us/sample - loss: 1.1793 - acc: 0.3961 - val_loss: 1.1776 - val_acc: 0.4837\n",
            "Epoch 273/1000\n",
            "611/611 [==============================] - 0s 413us/sample - loss: 1.1881 - acc: 0.4288 - val_loss: 1.1708 - val_acc: 0.4837\n",
            "Epoch 274/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.1958 - acc: 0.4370 - val_loss: 1.1655 - val_acc: 0.4183\n",
            "Epoch 275/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.1968 - acc: 0.4190 - val_loss: 1.1702 - val_acc: 0.4967\n",
            "Epoch 276/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.1840 - acc: 0.4321 - val_loss: 1.1679 - val_acc: 0.4444\n",
            "Epoch 277/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.1770 - acc: 0.4255 - val_loss: 1.1654 - val_acc: 0.4052\n",
            "Epoch 278/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.1747 - acc: 0.4468 - val_loss: 1.1656 - val_acc: 0.4510\n",
            "Epoch 279/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1871 - acc: 0.4075 - val_loss: 1.1634 - val_acc: 0.3987\n",
            "Epoch 280/1000\n",
            "611/611 [==============================] - 0s 376us/sample - loss: 1.1800 - acc: 0.4386 - val_loss: 1.1643 - val_acc: 0.4771\n",
            "Epoch 281/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1867 - acc: 0.4141 - val_loss: 1.1552 - val_acc: 0.4379\n",
            "Epoch 282/1000\n",
            "611/611 [==============================] - 0s 364us/sample - loss: 1.1696 - acc: 0.4452 - val_loss: 1.1684 - val_acc: 0.4902\n",
            "Epoch 283/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1883 - acc: 0.4272 - val_loss: 1.1559 - val_acc: 0.4510\n",
            "Epoch 284/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.1848 - acc: 0.4108 - val_loss: 1.1812 - val_acc: 0.5098\n",
            "Epoch 285/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1760 - acc: 0.4354 - val_loss: 1.1549 - val_acc: 0.4379\n",
            "Epoch 286/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1734 - acc: 0.4403 - val_loss: 1.1575 - val_acc: 0.4183\n",
            "Epoch 287/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.1707 - acc: 0.4223 - val_loss: 1.1535 - val_acc: 0.4379\n",
            "Epoch 288/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1669 - acc: 0.4452 - val_loss: 1.1500 - val_acc: 0.4444\n",
            "Epoch 289/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.1807 - acc: 0.4059 - val_loss: 1.1735 - val_acc: 0.4183\n",
            "Epoch 290/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1959 - acc: 0.4124 - val_loss: 1.1559 - val_acc: 0.4837\n",
            "Epoch 291/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 1.1787 - acc: 0.4403 - val_loss: 1.1584 - val_acc: 0.4771\n",
            "Epoch 292/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.1714 - acc: 0.4468 - val_loss: 1.1561 - val_acc: 0.4641\n",
            "Epoch 293/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1716 - acc: 0.4304 - val_loss: 1.1704 - val_acc: 0.4902\n",
            "Epoch 294/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1807 - acc: 0.4239 - val_loss: 1.1836 - val_acc: 0.5098\n",
            "Epoch 295/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1748 - acc: 0.4534 - val_loss: 1.1560 - val_acc: 0.4379\n",
            "Epoch 296/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1755 - acc: 0.4370 - val_loss: 1.1746 - val_acc: 0.5098\n",
            "Epoch 297/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.1756 - acc: 0.4304 - val_loss: 1.1577 - val_acc: 0.4706\n",
            "Epoch 298/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1906 - acc: 0.4010 - val_loss: 1.1519 - val_acc: 0.4118\n",
            "Epoch 299/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.1914 - acc: 0.4141 - val_loss: 1.1678 - val_acc: 0.4967\n",
            "Epoch 300/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.1765 - acc: 0.4452 - val_loss: 1.1812 - val_acc: 0.4052\n",
            "Epoch 301/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.1974 - acc: 0.4157 - val_loss: 1.1467 - val_acc: 0.4314\n",
            "Epoch 302/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1687 - acc: 0.4321 - val_loss: 1.1571 - val_acc: 0.4575\n",
            "Epoch 303/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1830 - acc: 0.4206 - val_loss: 1.1459 - val_acc: 0.4248\n",
            "Epoch 304/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1778 - acc: 0.4288 - val_loss: 1.1750 - val_acc: 0.5098\n",
            "Epoch 305/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.1800 - acc: 0.4157 - val_loss: 1.1711 - val_acc: 0.4902\n",
            "Epoch 306/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1773 - acc: 0.4288 - val_loss: 1.1437 - val_acc: 0.4248\n",
            "Epoch 307/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.1775 - acc: 0.4386 - val_loss: 1.1551 - val_acc: 0.4706\n",
            "Epoch 308/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.1680 - acc: 0.4615 - val_loss: 1.1941 - val_acc: 0.4967\n",
            "Epoch 309/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1667 - acc: 0.4484 - val_loss: 1.1539 - val_acc: 0.4641\n",
            "Epoch 310/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1779 - acc: 0.4517 - val_loss: 1.1469 - val_acc: 0.4771\n",
            "Epoch 311/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1594 - acc: 0.4255 - val_loss: 1.1445 - val_acc: 0.4183\n",
            "Epoch 312/1000\n",
            "611/611 [==============================] - 0s 374us/sample - loss: 1.1858 - acc: 0.4092 - val_loss: 1.1418 - val_acc: 0.4314\n",
            "Epoch 313/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1592 - acc: 0.4452 - val_loss: 1.1893 - val_acc: 0.4967\n",
            "Epoch 314/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1784 - acc: 0.4092 - val_loss: 1.1594 - val_acc: 0.4967\n",
            "Epoch 315/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1699 - acc: 0.4190 - val_loss: 1.1478 - val_acc: 0.4641\n",
            "Epoch 316/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1669 - acc: 0.4435 - val_loss: 1.1781 - val_acc: 0.5033\n",
            "Epoch 317/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.1775 - acc: 0.4403 - val_loss: 1.1594 - val_acc: 0.4967\n",
            "Epoch 318/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1752 - acc: 0.4173 - val_loss: 1.1444 - val_acc: 0.4771\n",
            "Epoch 319/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.1633 - acc: 0.4632 - val_loss: 1.1375 - val_acc: 0.4248\n",
            "Epoch 320/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.1756 - acc: 0.4108 - val_loss: 1.1503 - val_acc: 0.4902\n",
            "Epoch 321/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1618 - acc: 0.4272 - val_loss: 1.1400 - val_acc: 0.4510\n",
            "Epoch 322/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.1731 - acc: 0.4452 - val_loss: 1.1383 - val_acc: 0.4248\n",
            "Epoch 323/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1768 - acc: 0.4370 - val_loss: 1.1545 - val_acc: 0.5033\n",
            "Epoch 324/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1770 - acc: 0.4272 - val_loss: 1.1431 - val_acc: 0.4183\n",
            "Epoch 325/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1866 - acc: 0.4288 - val_loss: 1.1364 - val_acc: 0.4379\n",
            "Epoch 326/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.1678 - acc: 0.4337 - val_loss: 1.1637 - val_acc: 0.5033\n",
            "Epoch 327/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.1475 - acc: 0.4664 - val_loss: 1.1471 - val_acc: 0.4902\n",
            "Epoch 328/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1670 - acc: 0.4517 - val_loss: 1.1338 - val_acc: 0.4706\n",
            "Epoch 329/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.1549 - acc: 0.4403 - val_loss: 1.2019 - val_acc: 0.4902\n",
            "Epoch 330/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1671 - acc: 0.4452 - val_loss: 1.1367 - val_acc: 0.4837\n",
            "Epoch 331/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.1502 - acc: 0.4484 - val_loss: 1.1755 - val_acc: 0.4837\n",
            "Epoch 332/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.1722 - acc: 0.4239 - val_loss: 1.1394 - val_acc: 0.4837\n",
            "Epoch 333/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1614 - acc: 0.4288 - val_loss: 1.1423 - val_acc: 0.4771\n",
            "Epoch 334/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.1567 - acc: 0.4435 - val_loss: 1.1703 - val_acc: 0.4837\n",
            "Epoch 335/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1630 - acc: 0.4452 - val_loss: 1.1636 - val_acc: 0.4967\n",
            "Epoch 336/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.1461 - acc: 0.4386 - val_loss: 1.1304 - val_acc: 0.4771\n",
            "Epoch 337/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.1638 - acc: 0.4239 - val_loss: 1.1301 - val_acc: 0.4510\n",
            "Epoch 338/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.1519 - acc: 0.4779 - val_loss: 1.1337 - val_acc: 0.4248\n",
            "Epoch 339/1000\n",
            "611/611 [==============================] - 0s 390us/sample - loss: 1.1735 - acc: 0.4386 - val_loss: 1.1389 - val_acc: 0.4967\n",
            "Epoch 340/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.1570 - acc: 0.4206 - val_loss: 1.1638 - val_acc: 0.5033\n",
            "Epoch 341/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1461 - acc: 0.4304 - val_loss: 1.1310 - val_acc: 0.4183\n",
            "Epoch 342/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1673 - acc: 0.4173 - val_loss: 1.1389 - val_acc: 0.4118\n",
            "Epoch 343/1000\n",
            "611/611 [==============================] - 0s 374us/sample - loss: 1.1436 - acc: 0.4468 - val_loss: 1.1665 - val_acc: 0.4967\n",
            "Epoch 344/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1618 - acc: 0.4288 - val_loss: 1.1388 - val_acc: 0.4902\n",
            "Epoch 345/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1603 - acc: 0.4337 - val_loss: 1.1768 - val_acc: 0.4902\n",
            "Epoch 346/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1653 - acc: 0.4026 - val_loss: 1.1580 - val_acc: 0.4118\n",
            "Epoch 347/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.1578 - acc: 0.4403 - val_loss: 1.1650 - val_acc: 0.4967\n",
            "Epoch 348/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1578 - acc: 0.4452 - val_loss: 1.1253 - val_acc: 0.4248\n",
            "Epoch 349/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1458 - acc: 0.4452 - val_loss: 1.1257 - val_acc: 0.4248\n",
            "Epoch 350/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1366 - acc: 0.4288 - val_loss: 1.1576 - val_acc: 0.5033\n",
            "Epoch 351/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.1690 - acc: 0.4239 - val_loss: 1.1241 - val_acc: 0.4575\n",
            "Epoch 352/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1617 - acc: 0.4468 - val_loss: 1.1653 - val_acc: 0.4444\n",
            "Epoch 353/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.1629 - acc: 0.4435 - val_loss: 1.1269 - val_acc: 0.4967\n",
            "Epoch 354/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1468 - acc: 0.4468 - val_loss: 1.1230 - val_acc: 0.4837\n",
            "Epoch 355/1000\n",
            "611/611 [==============================] - 0s 312us/sample - loss: 1.1588 - acc: 0.4304 - val_loss: 1.1491 - val_acc: 0.5098\n",
            "Epoch 356/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1606 - acc: 0.4484 - val_loss: 1.1347 - val_acc: 0.4967\n",
            "Epoch 357/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1383 - acc: 0.4664 - val_loss: 1.1223 - val_acc: 0.4444\n",
            "Epoch 358/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1521 - acc: 0.4746 - val_loss: 1.1432 - val_acc: 0.4248\n",
            "Epoch 359/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1549 - acc: 0.4304 - val_loss: 1.1598 - val_acc: 0.4967\n",
            "Epoch 360/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1354 - acc: 0.4550 - val_loss: 1.1204 - val_acc: 0.4837\n",
            "Epoch 361/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.1259 - acc: 0.4583 - val_loss: 1.1239 - val_acc: 0.4248\n",
            "Epoch 362/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1298 - acc: 0.4615 - val_loss: 1.1507 - val_acc: 0.5033\n",
            "Epoch 363/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.1415 - acc: 0.4370 - val_loss: 1.1199 - val_acc: 0.4902\n",
            "Epoch 364/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.1394 - acc: 0.4714 - val_loss: 1.1169 - val_acc: 0.4902\n",
            "Epoch 365/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.1610 - acc: 0.4484 - val_loss: 1.1219 - val_acc: 0.4837\n",
            "Epoch 366/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1392 - acc: 0.4550 - val_loss: 1.1595 - val_acc: 0.4967\n",
            "Epoch 367/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1551 - acc: 0.4370 - val_loss: 1.1162 - val_acc: 0.4837\n",
            "Epoch 368/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.1630 - acc: 0.4370 - val_loss: 1.1163 - val_acc: 0.4706\n",
            "Epoch 369/1000\n",
            "611/611 [==============================] - 0s 389us/sample - loss: 1.1490 - acc: 0.4534 - val_loss: 1.1355 - val_acc: 0.5033\n",
            "Epoch 370/1000\n",
            "611/611 [==============================] - 0s 363us/sample - loss: 1.1479 - acc: 0.4255 - val_loss: 1.1559 - val_acc: 0.5033\n",
            "Epoch 371/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.1616 - acc: 0.4566 - val_loss: 1.1161 - val_acc: 0.4706\n",
            "Epoch 372/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.1475 - acc: 0.4599 - val_loss: 1.1201 - val_acc: 0.4837\n",
            "Epoch 373/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.1479 - acc: 0.4452 - val_loss: 1.1414 - val_acc: 0.5098\n",
            "Epoch 374/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.1542 - acc: 0.4239 - val_loss: 1.1462 - val_acc: 0.5098\n",
            "Epoch 375/1000\n",
            "611/611 [==============================] - 0s 401us/sample - loss: 1.1626 - acc: 0.4059 - val_loss: 1.1327 - val_acc: 0.4183\n",
            "Epoch 376/1000\n",
            "611/611 [==============================] - 0s 372us/sample - loss: 1.1511 - acc: 0.4484 - val_loss: 1.1133 - val_acc: 0.4706\n",
            "Epoch 377/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.1447 - acc: 0.4632 - val_loss: 1.1122 - val_acc: 0.4967\n",
            "Epoch 378/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.1274 - acc: 0.4288 - val_loss: 1.1130 - val_acc: 0.4837\n",
            "Epoch 379/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.1331 - acc: 0.4501 - val_loss: 1.1816 - val_acc: 0.4902\n",
            "Epoch 380/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1451 - acc: 0.4534 - val_loss: 1.1128 - val_acc: 0.4641\n",
            "Epoch 381/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.1364 - acc: 0.4795 - val_loss: 1.1120 - val_acc: 0.4641\n",
            "Epoch 382/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1399 - acc: 0.4435 - val_loss: 1.1227 - val_acc: 0.4248\n",
            "Epoch 383/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1420 - acc: 0.4517 - val_loss: 1.1507 - val_acc: 0.5163\n",
            "Epoch 384/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.1340 - acc: 0.4664 - val_loss: 1.1456 - val_acc: 0.5098\n",
            "Epoch 385/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.1421 - acc: 0.4664 - val_loss: 1.1083 - val_acc: 0.4837\n",
            "Epoch 386/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1487 - acc: 0.4403 - val_loss: 1.1290 - val_acc: 0.5033\n",
            "Epoch 387/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.1267 - acc: 0.4615 - val_loss: 1.1071 - val_acc: 0.4902\n",
            "Epoch 388/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.1469 - acc: 0.4484 - val_loss: 1.1094 - val_acc: 0.4706\n",
            "Epoch 389/1000\n",
            "611/611 [==============================] - 0s 369us/sample - loss: 1.1112 - acc: 0.4828 - val_loss: 1.1117 - val_acc: 0.4510\n",
            "Epoch 390/1000\n",
            "611/611 [==============================] - 0s 429us/sample - loss: 1.1455 - acc: 0.4255 - val_loss: 1.1168 - val_acc: 0.4444\n",
            "Epoch 391/1000\n",
            "611/611 [==============================] - 0s 363us/sample - loss: 1.1345 - acc: 0.4632 - val_loss: 1.1680 - val_acc: 0.4967\n",
            "Epoch 392/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1459 - acc: 0.4566 - val_loss: 1.1429 - val_acc: 0.5098\n",
            "Epoch 393/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1420 - acc: 0.4255 - val_loss: 1.1302 - val_acc: 0.5098\n",
            "Epoch 394/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1290 - acc: 0.4599 - val_loss: 1.1081 - val_acc: 0.4771\n",
            "Epoch 395/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1383 - acc: 0.4223 - val_loss: 1.1066 - val_acc: 0.4837\n",
            "Epoch 396/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1338 - acc: 0.4714 - val_loss: 1.1338 - val_acc: 0.4248\n",
            "Epoch 397/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.1392 - acc: 0.4550 - val_loss: 1.1537 - val_acc: 0.4837\n",
            "Epoch 398/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.1257 - acc: 0.4534 - val_loss: 1.1505 - val_acc: 0.4379\n",
            "Epoch 399/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1389 - acc: 0.4370 - val_loss: 1.1031 - val_acc: 0.4837\n",
            "Epoch 400/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1256 - acc: 0.4632 - val_loss: 1.1034 - val_acc: 0.4902\n",
            "Epoch 401/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.1329 - acc: 0.4566 - val_loss: 1.1819 - val_acc: 0.4706\n",
            "Epoch 402/1000\n",
            "611/611 [==============================] - 0s 375us/sample - loss: 1.1416 - acc: 0.4452 - val_loss: 1.1487 - val_acc: 0.5033\n",
            "Epoch 403/1000\n",
            "611/611 [==============================] - 0s 357us/sample - loss: 1.1383 - acc: 0.4386 - val_loss: 1.1008 - val_acc: 0.4967\n",
            "Epoch 404/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.1481 - acc: 0.4615 - val_loss: 1.1156 - val_acc: 0.4902\n",
            "Epoch 405/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.1393 - acc: 0.4583 - val_loss: 1.1051 - val_acc: 0.4967\n",
            "Epoch 406/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.1264 - acc: 0.4583 - val_loss: 1.1054 - val_acc: 0.4967\n",
            "Epoch 407/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.1200 - acc: 0.4321 - val_loss: 1.1478 - val_acc: 0.4314\n",
            "Epoch 408/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1236 - acc: 0.4714 - val_loss: 1.1253 - val_acc: 0.5033\n",
            "Epoch 409/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.1364 - acc: 0.4664 - val_loss: 1.1233 - val_acc: 0.5033\n",
            "Epoch 410/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.1295 - acc: 0.4583 - val_loss: 1.1025 - val_acc: 0.4967\n",
            "Epoch 411/1000\n",
            "611/611 [==============================] - 0s 369us/sample - loss: 1.1297 - acc: 0.4746 - val_loss: 1.1211 - val_acc: 0.5163\n",
            "Epoch 412/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.1495 - acc: 0.4599 - val_loss: 1.1106 - val_acc: 0.4967\n",
            "Epoch 413/1000\n",
            "611/611 [==============================] - 0s 416us/sample - loss: 1.1183 - acc: 0.4468 - val_loss: 1.0990 - val_acc: 0.5033\n",
            "Epoch 414/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1388 - acc: 0.4321 - val_loss: 1.1796 - val_acc: 0.4706\n",
            "Epoch 415/1000\n",
            "611/611 [==============================] - 0s 367us/sample - loss: 1.1109 - acc: 0.4795 - val_loss: 1.0996 - val_acc: 0.4902\n",
            "Epoch 416/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1315 - acc: 0.4566 - val_loss: 1.1286 - val_acc: 0.5098\n",
            "Epoch 417/1000\n",
            "611/611 [==============================] - 0s 374us/sample - loss: 1.1403 - acc: 0.4599 - val_loss: 1.0949 - val_acc: 0.5098\n",
            "Epoch 418/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1301 - acc: 0.4550 - val_loss: 1.1059 - val_acc: 0.4837\n",
            "Epoch 419/1000\n",
            "611/611 [==============================] - 0s 428us/sample - loss: 1.1187 - acc: 0.4763 - val_loss: 1.0957 - val_acc: 0.4967\n",
            "Epoch 420/1000\n",
            "611/611 [==============================] - 0s 372us/sample - loss: 1.1267 - acc: 0.4468 - val_loss: 1.1435 - val_acc: 0.5033\n",
            "Epoch 421/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.1228 - acc: 0.4681 - val_loss: 1.2064 - val_acc: 0.4575\n",
            "Epoch 422/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1426 - acc: 0.4501 - val_loss: 1.0941 - val_acc: 0.4967\n",
            "Epoch 423/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1026 - acc: 0.4877 - val_loss: 1.1316 - val_acc: 0.5163\n",
            "Epoch 424/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1244 - acc: 0.4697 - val_loss: 1.1447 - val_acc: 0.5098\n",
            "Epoch 425/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1398 - acc: 0.4304 - val_loss: 1.1852 - val_acc: 0.4641\n",
            "Epoch 426/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.1358 - acc: 0.4566 - val_loss: 1.0989 - val_acc: 0.4967\n",
            "Epoch 427/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.1150 - acc: 0.4697 - val_loss: 1.0928 - val_acc: 0.5033\n",
            "Epoch 428/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.1247 - acc: 0.4484 - val_loss: 1.1151 - val_acc: 0.4248\n",
            "Epoch 429/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.1109 - acc: 0.4763 - val_loss: 1.1095 - val_acc: 0.5098\n",
            "Epoch 430/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1197 - acc: 0.4730 - val_loss: 1.1426 - val_acc: 0.4641\n",
            "Epoch 431/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.1323 - acc: 0.4419 - val_loss: 1.1062 - val_acc: 0.4771\n",
            "Epoch 432/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1304 - acc: 0.4484 - val_loss: 1.1027 - val_acc: 0.5033\n",
            "Epoch 433/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.1341 - acc: 0.4550 - val_loss: 1.0930 - val_acc: 0.4771\n",
            "Epoch 434/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.1167 - acc: 0.4550 - val_loss: 1.1110 - val_acc: 0.5098\n",
            "Epoch 435/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.1190 - acc: 0.4501 - val_loss: 1.1128 - val_acc: 0.5098\n",
            "Epoch 436/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.1029 - acc: 0.4763 - val_loss: 1.1141 - val_acc: 0.5098\n",
            "Epoch 437/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.1088 - acc: 0.4828 - val_loss: 1.1527 - val_acc: 0.4902\n",
            "Epoch 438/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1305 - acc: 0.4517 - val_loss: 1.0974 - val_acc: 0.4837\n",
            "Epoch 439/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.1088 - acc: 0.4714 - val_loss: 1.0880 - val_acc: 0.4902\n",
            "Epoch 440/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.1308 - acc: 0.4632 - val_loss: 1.0945 - val_acc: 0.4902\n",
            "Epoch 441/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.1098 - acc: 0.4861 - val_loss: 1.0901 - val_acc: 0.4902\n",
            "Epoch 442/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.1059 - acc: 0.4599 - val_loss: 1.0868 - val_acc: 0.5033\n",
            "Epoch 443/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1353 - acc: 0.4599 - val_loss: 1.1094 - val_acc: 0.5098\n",
            "Epoch 444/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1269 - acc: 0.4648 - val_loss: 1.1314 - val_acc: 0.5163\n",
            "Epoch 445/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.1229 - acc: 0.4517 - val_loss: 1.1052 - val_acc: 0.5163\n",
            "Epoch 446/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1107 - acc: 0.4714 - val_loss: 1.0873 - val_acc: 0.5033\n",
            "Epoch 447/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.1182 - acc: 0.4468 - val_loss: 1.0867 - val_acc: 0.4902\n",
            "Epoch 448/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1122 - acc: 0.4779 - val_loss: 1.1382 - val_acc: 0.5098\n",
            "Epoch 449/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.1364 - acc: 0.4386 - val_loss: 1.0887 - val_acc: 0.4837\n",
            "Epoch 450/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.1216 - acc: 0.4730 - val_loss: 1.1233 - val_acc: 0.5098\n",
            "Epoch 451/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.1243 - acc: 0.4632 - val_loss: 1.0901 - val_acc: 0.4967\n",
            "Epoch 452/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.1055 - acc: 0.4812 - val_loss: 1.0959 - val_acc: 0.4902\n",
            "Epoch 453/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.1391 - acc: 0.4550 - val_loss: 1.1485 - val_acc: 0.4967\n",
            "Epoch 454/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0862 - acc: 0.4894 - val_loss: 1.1448 - val_acc: 0.5033\n",
            "Epoch 455/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0985 - acc: 0.4812 - val_loss: 1.1095 - val_acc: 0.5098\n",
            "Epoch 456/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1209 - acc: 0.4566 - val_loss: 1.1182 - val_acc: 0.5163\n",
            "Epoch 457/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.1095 - acc: 0.4910 - val_loss: 1.0880 - val_acc: 0.4967\n",
            "Epoch 458/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.1053 - acc: 0.4714 - val_loss: 1.1111 - val_acc: 0.5098\n",
            "Epoch 459/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.1260 - acc: 0.4583 - val_loss: 1.0852 - val_acc: 0.4967\n",
            "Epoch 460/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.1014 - acc: 0.4730 - val_loss: 1.0887 - val_acc: 0.4771\n",
            "Epoch 461/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0970 - acc: 0.5090 - val_loss: 1.0835 - val_acc: 0.4967\n",
            "Epoch 462/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1108 - acc: 0.4779 - val_loss: 1.0799 - val_acc: 0.5098\n",
            "Epoch 463/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.1064 - acc: 0.4763 - val_loss: 1.0823 - val_acc: 0.4967\n",
            "Epoch 464/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1036 - acc: 0.4812 - val_loss: 1.1249 - val_acc: 0.5163\n",
            "Epoch 465/1000\n",
            "611/611 [==============================] - 0s 367us/sample - loss: 1.1063 - acc: 0.4697 - val_loss: 1.0808 - val_acc: 0.5033\n",
            "Epoch 466/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0965 - acc: 0.4763 - val_loss: 1.1067 - val_acc: 0.5098\n",
            "Epoch 467/1000\n",
            "611/611 [==============================] - 0s 400us/sample - loss: 1.1016 - acc: 0.4746 - val_loss: 1.0923 - val_acc: 0.5098\n",
            "Epoch 468/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1126 - acc: 0.4746 - val_loss: 1.0798 - val_acc: 0.5033\n",
            "Epoch 469/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.1169 - acc: 0.4746 - val_loss: 1.0830 - val_acc: 0.4967\n",
            "Epoch 470/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.1389 - acc: 0.4599 - val_loss: 1.1069 - val_acc: 0.5033\n",
            "Epoch 471/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.1046 - acc: 0.4648 - val_loss: 1.0818 - val_acc: 0.4967\n",
            "Epoch 472/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0984 - acc: 0.4681 - val_loss: 1.0780 - val_acc: 0.4902\n",
            "Epoch 473/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.0935 - acc: 0.4779 - val_loss: 1.1066 - val_acc: 0.5163\n",
            "Epoch 474/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1011 - acc: 0.5041 - val_loss: 1.1047 - val_acc: 0.5033\n",
            "Epoch 475/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.0987 - acc: 0.4517 - val_loss: 1.1003 - val_acc: 0.4837\n",
            "Epoch 476/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.1068 - acc: 0.4484 - val_loss: 1.1095 - val_acc: 0.5098\n",
            "Epoch 477/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.0978 - acc: 0.4828 - val_loss: 1.0770 - val_acc: 0.4967\n",
            "Epoch 478/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0853 - acc: 0.5057 - val_loss: 1.0758 - val_acc: 0.5098\n",
            "Epoch 479/1000\n",
            "611/611 [==============================] - 0s 444us/sample - loss: 1.1055 - acc: 0.4648 - val_loss: 1.0795 - val_acc: 0.4967\n",
            "Epoch 480/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.1061 - acc: 0.4779 - val_loss: 1.1261 - val_acc: 0.5033\n",
            "Epoch 481/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0935 - acc: 0.4910 - val_loss: 1.0756 - val_acc: 0.5098\n",
            "Epoch 482/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.1032 - acc: 0.4845 - val_loss: 1.1313 - val_acc: 0.5033\n",
            "Epoch 483/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.1073 - acc: 0.4697 - val_loss: 1.0861 - val_acc: 0.4967\n",
            "Epoch 484/1000\n",
            "611/611 [==============================] - 0s 419us/sample - loss: 1.1054 - acc: 0.4664 - val_loss: 1.1018 - val_acc: 0.5033\n",
            "Epoch 485/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.0890 - acc: 0.4943 - val_loss: 1.0841 - val_acc: 0.4967\n",
            "Epoch 486/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.1043 - acc: 0.5057 - val_loss: 1.0865 - val_acc: 0.4902\n",
            "Epoch 487/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0969 - acc: 0.4894 - val_loss: 1.1055 - val_acc: 0.5033\n",
            "Epoch 488/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0991 - acc: 0.4910 - val_loss: 1.0754 - val_acc: 0.4902\n",
            "Epoch 489/1000\n",
            "611/611 [==============================] - 0s 435us/sample - loss: 1.0981 - acc: 0.4779 - val_loss: 1.1225 - val_acc: 0.4510\n",
            "Epoch 490/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.1123 - acc: 0.4599 - val_loss: 1.0738 - val_acc: 0.4902\n",
            "Epoch 491/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0956 - acc: 0.4730 - val_loss: 1.0795 - val_acc: 0.5033\n",
            "Epoch 492/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0936 - acc: 0.4926 - val_loss: 1.0739 - val_acc: 0.4902\n",
            "Epoch 493/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.1076 - acc: 0.4975 - val_loss: 1.0765 - val_acc: 0.4837\n",
            "Epoch 494/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.0816 - acc: 0.5090 - val_loss: 1.1160 - val_acc: 0.5229\n",
            "Epoch 495/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.1035 - acc: 0.4714 - val_loss: 1.0710 - val_acc: 0.4902\n",
            "Epoch 496/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0985 - acc: 0.4648 - val_loss: 1.0845 - val_acc: 0.4967\n",
            "Epoch 497/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.0750 - acc: 0.4861 - val_loss: 1.1207 - val_acc: 0.4510\n",
            "Epoch 498/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0957 - acc: 0.5008 - val_loss: 1.1201 - val_acc: 0.5229\n",
            "Epoch 499/1000\n",
            "611/611 [==============================] - 0s 448us/sample - loss: 1.1041 - acc: 0.4779 - val_loss: 1.0690 - val_acc: 0.5033\n",
            "Epoch 500/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0908 - acc: 0.4795 - val_loss: 1.1316 - val_acc: 0.5033\n",
            "Epoch 501/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0844 - acc: 0.4894 - val_loss: 1.0960 - val_acc: 0.4837\n",
            "Epoch 502/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.1105 - acc: 0.4910 - val_loss: 1.0810 - val_acc: 0.4837\n",
            "Epoch 503/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1002 - acc: 0.4583 - val_loss: 1.0905 - val_acc: 0.4771\n",
            "Epoch 504/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0903 - acc: 0.5155 - val_loss: 1.0682 - val_acc: 0.4902\n",
            "Epoch 505/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.1019 - acc: 0.4926 - val_loss: 1.0713 - val_acc: 0.5033\n",
            "Epoch 506/1000\n",
            "611/611 [==============================] - 0s 379us/sample - loss: 1.0844 - acc: 0.5074 - val_loss: 1.0671 - val_acc: 0.4967\n",
            "Epoch 507/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.1010 - acc: 0.4648 - val_loss: 1.0767 - val_acc: 0.4902\n",
            "Epoch 508/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1019 - acc: 0.4992 - val_loss: 1.0668 - val_acc: 0.5033\n",
            "Epoch 509/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0931 - acc: 0.4992 - val_loss: 1.1132 - val_acc: 0.5163\n",
            "Epoch 510/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0877 - acc: 0.4779 - val_loss: 1.0734 - val_acc: 0.4967\n",
            "Epoch 511/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0907 - acc: 0.5139 - val_loss: 1.2115 - val_acc: 0.4641\n",
            "Epoch 512/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.1118 - acc: 0.4681 - val_loss: 1.1282 - val_acc: 0.5098\n",
            "Epoch 513/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0935 - acc: 0.4746 - val_loss: 1.1123 - val_acc: 0.5229\n",
            "Epoch 514/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0804 - acc: 0.4828 - val_loss: 1.0836 - val_acc: 0.5163\n",
            "Epoch 515/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0990 - acc: 0.4877 - val_loss: 1.0650 - val_acc: 0.4902\n",
            "Epoch 516/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0881 - acc: 0.5123 - val_loss: 1.0744 - val_acc: 0.5163\n",
            "Epoch 517/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0858 - acc: 0.4779 - val_loss: 1.0686 - val_acc: 0.4902\n",
            "Epoch 518/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.1020 - acc: 0.4583 - val_loss: 1.1215 - val_acc: 0.5098\n",
            "Epoch 519/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0858 - acc: 0.4648 - val_loss: 1.1109 - val_acc: 0.5163\n",
            "Epoch 520/1000\n",
            "611/611 [==============================] - 0s 312us/sample - loss: 1.0869 - acc: 0.4730 - val_loss: 1.0642 - val_acc: 0.4902\n",
            "Epoch 521/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0940 - acc: 0.4746 - val_loss: 1.1457 - val_acc: 0.4967\n",
            "Epoch 522/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.1038 - acc: 0.4975 - val_loss: 1.0712 - val_acc: 0.5033\n",
            "Epoch 523/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0879 - acc: 0.4714 - val_loss: 1.0655 - val_acc: 0.5098\n",
            "Epoch 524/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.0957 - acc: 0.4877 - val_loss: 1.0717 - val_acc: 0.5033\n",
            "Epoch 525/1000\n",
            "611/611 [==============================] - 0s 308us/sample - loss: 1.0741 - acc: 0.4845 - val_loss: 1.0823 - val_acc: 0.5098\n",
            "Epoch 526/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0963 - acc: 0.4714 - val_loss: 1.1324 - val_acc: 0.4967\n",
            "Epoch 527/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.1024 - acc: 0.4681 - val_loss: 1.1190 - val_acc: 0.5098\n",
            "Epoch 528/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0879 - acc: 0.4828 - val_loss: 1.0644 - val_acc: 0.5033\n",
            "Epoch 529/1000\n",
            "611/611 [==============================] - 0s 382us/sample - loss: 1.0811 - acc: 0.4992 - val_loss: 1.0661 - val_acc: 0.4967\n",
            "Epoch 530/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.1037 - acc: 0.4615 - val_loss: 1.0955 - val_acc: 0.5033\n",
            "Epoch 531/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0893 - acc: 0.4877 - val_loss: 1.0637 - val_acc: 0.4967\n",
            "Epoch 532/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0766 - acc: 0.4714 - val_loss: 1.0693 - val_acc: 0.5033\n",
            "Epoch 533/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.0934 - acc: 0.4812 - val_loss: 1.0966 - val_acc: 0.5098\n",
            "Epoch 534/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0936 - acc: 0.4943 - val_loss: 1.0651 - val_acc: 0.5098\n",
            "Epoch 535/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0840 - acc: 0.4910 - val_loss: 1.0631 - val_acc: 0.5098\n",
            "Epoch 536/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0786 - acc: 0.4861 - val_loss: 1.0620 - val_acc: 0.5033\n",
            "Epoch 537/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0830 - acc: 0.5155 - val_loss: 1.0687 - val_acc: 0.4967\n",
            "Epoch 538/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.0914 - acc: 0.4877 - val_loss: 1.0643 - val_acc: 0.5033\n",
            "Epoch 539/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1099 - acc: 0.4468 - val_loss: 1.0976 - val_acc: 0.5098\n",
            "Epoch 540/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0957 - acc: 0.4779 - val_loss: 1.1118 - val_acc: 0.5163\n",
            "Epoch 541/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.0857 - acc: 0.4943 - val_loss: 1.0652 - val_acc: 0.5163\n",
            "Epoch 542/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.1006 - acc: 0.4877 - val_loss: 1.1210 - val_acc: 0.5033\n",
            "Epoch 543/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.0776 - acc: 0.4910 - val_loss: 1.0592 - val_acc: 0.5098\n",
            "Epoch 544/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0760 - acc: 0.4894 - val_loss: 1.0979 - val_acc: 0.4967\n",
            "Epoch 545/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0778 - acc: 0.4926 - val_loss: 1.0861 - val_acc: 0.4967\n",
            "Epoch 546/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.1010 - acc: 0.4746 - val_loss: 1.0598 - val_acc: 0.5033\n",
            "Epoch 547/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0971 - acc: 0.4697 - val_loss: 1.0719 - val_acc: 0.5098\n",
            "Epoch 548/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0875 - acc: 0.4975 - val_loss: 1.0596 - val_acc: 0.4967\n",
            "Epoch 549/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0793 - acc: 0.4992 - val_loss: 1.0822 - val_acc: 0.5163\n",
            "Epoch 550/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0937 - acc: 0.4795 - val_loss: 1.1209 - val_acc: 0.4967\n",
            "Epoch 551/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.0828 - acc: 0.5057 - val_loss: 1.0606 - val_acc: 0.4967\n",
            "Epoch 552/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0771 - acc: 0.4910 - val_loss: 1.1279 - val_acc: 0.4837\n",
            "Epoch 553/1000\n",
            "611/611 [==============================] - 0s 390us/sample - loss: 1.0826 - acc: 0.4795 - val_loss: 1.0618 - val_acc: 0.5033\n",
            "Epoch 554/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0934 - acc: 0.4795 - val_loss: 1.0685 - val_acc: 0.5033\n",
            "Epoch 555/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0920 - acc: 0.4910 - val_loss: 1.0608 - val_acc: 0.5163\n",
            "Epoch 556/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0856 - acc: 0.4828 - val_loss: 1.0691 - val_acc: 0.5033\n",
            "Epoch 557/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0720 - acc: 0.4861 - val_loss: 1.0905 - val_acc: 0.4902\n",
            "Epoch 558/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0793 - acc: 0.4730 - val_loss: 1.0628 - val_acc: 0.5098\n",
            "Epoch 559/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0890 - acc: 0.4583 - val_loss: 1.0795 - val_acc: 0.5098\n",
            "Epoch 560/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0629 - acc: 0.4959 - val_loss: 1.0610 - val_acc: 0.5033\n",
            "Epoch 561/1000\n",
            "611/611 [==============================] - 0s 386us/sample - loss: 1.0933 - acc: 0.4812 - val_loss: 1.0589 - val_acc: 0.5098\n",
            "Epoch 562/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0870 - acc: 0.4828 - val_loss: 1.0761 - val_acc: 0.4967\n",
            "Epoch 563/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0711 - acc: 0.5057 - val_loss: 1.0579 - val_acc: 0.5033\n",
            "Epoch 564/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.0718 - acc: 0.4910 - val_loss: 1.0744 - val_acc: 0.5163\n",
            "Epoch 565/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0778 - acc: 0.5172 - val_loss: 1.0565 - val_acc: 0.5033\n",
            "Epoch 566/1000\n",
            "611/611 [==============================] - 0s 383us/sample - loss: 1.0628 - acc: 0.4894 - val_loss: 1.0686 - val_acc: 0.5033\n",
            "Epoch 567/1000\n",
            "611/611 [==============================] - 0s 390us/sample - loss: 1.0913 - acc: 0.4795 - val_loss: 1.0699 - val_acc: 0.5033\n",
            "Epoch 568/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0813 - acc: 0.4845 - val_loss: 1.0542 - val_acc: 0.5163\n",
            "Epoch 569/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.1024 - acc: 0.4779 - val_loss: 1.0546 - val_acc: 0.5163\n",
            "Epoch 570/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.0621 - acc: 0.5123 - val_loss: 1.0570 - val_acc: 0.5229\n",
            "Epoch 571/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0761 - acc: 0.4975 - val_loss: 1.0570 - val_acc: 0.5033\n",
            "Epoch 572/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.0816 - acc: 0.5074 - val_loss: 1.0575 - val_acc: 0.4967\n",
            "Epoch 573/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0764 - acc: 0.4697 - val_loss: 1.0987 - val_acc: 0.5098\n",
            "Epoch 574/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0844 - acc: 0.4926 - val_loss: 1.0570 - val_acc: 0.4967\n",
            "Epoch 575/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0781 - acc: 0.4992 - val_loss: 1.0674 - val_acc: 0.5033\n",
            "Epoch 576/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0813 - acc: 0.4746 - val_loss: 1.0820 - val_acc: 0.5229\n",
            "Epoch 577/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0794 - acc: 0.4615 - val_loss: 1.0615 - val_acc: 0.5163\n",
            "Epoch 578/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0695 - acc: 0.4910 - val_loss: 1.0978 - val_acc: 0.4575\n",
            "Epoch 579/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.0706 - acc: 0.4926 - val_loss: 1.0552 - val_acc: 0.5033\n",
            "Epoch 580/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0668 - acc: 0.4861 - val_loss: 1.0720 - val_acc: 0.5033\n",
            "Epoch 581/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0746 - acc: 0.4795 - val_loss: 1.0582 - val_acc: 0.5229\n",
            "Epoch 582/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0984 - acc: 0.4877 - val_loss: 1.0641 - val_acc: 0.5163\n",
            "Epoch 583/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 1.0971 - acc: 0.4894 - val_loss: 1.0535 - val_acc: 0.5229\n",
            "Epoch 584/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0713 - acc: 0.5041 - val_loss: 1.0927 - val_acc: 0.5098\n",
            "Epoch 585/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0965 - acc: 0.5008 - val_loss: 1.0697 - val_acc: 0.5033\n",
            "Epoch 586/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0700 - acc: 0.5025 - val_loss: 1.0777 - val_acc: 0.5033\n",
            "Epoch 587/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0713 - acc: 0.4926 - val_loss: 1.0495 - val_acc: 0.5033\n",
            "Epoch 588/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0837 - acc: 0.4861 - val_loss: 1.0523 - val_acc: 0.5294\n",
            "Epoch 589/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.0804 - acc: 0.4910 - val_loss: 1.0625 - val_acc: 0.5033\n",
            "Epoch 590/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0725 - acc: 0.4828 - val_loss: 1.0985 - val_acc: 0.5033\n",
            "Epoch 591/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0499 - acc: 0.5155 - val_loss: 1.0925 - val_acc: 0.5033\n",
            "Epoch 592/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0785 - acc: 0.5074 - val_loss: 1.0571 - val_acc: 0.4967\n",
            "Epoch 593/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0750 - acc: 0.4828 - val_loss: 1.0534 - val_acc: 0.5294\n",
            "Epoch 594/1000\n",
            "611/611 [==============================] - 0s 371us/sample - loss: 1.0450 - acc: 0.5270 - val_loss: 1.0932 - val_acc: 0.5033\n",
            "Epoch 595/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0641 - acc: 0.4877 - val_loss: 1.0856 - val_acc: 0.5098\n",
            "Epoch 596/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0547 - acc: 0.4975 - val_loss: 1.0508 - val_acc: 0.5294\n",
            "Epoch 597/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0641 - acc: 0.5074 - val_loss: 1.1118 - val_acc: 0.4706\n",
            "Epoch 598/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0645 - acc: 0.4959 - val_loss: 1.0462 - val_acc: 0.5229\n",
            "Epoch 599/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.0747 - acc: 0.4943 - val_loss: 1.0638 - val_acc: 0.5033\n",
            "Epoch 600/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.0994 - acc: 0.4664 - val_loss: 1.0764 - val_acc: 0.5098\n",
            "Epoch 601/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0794 - acc: 0.4910 - val_loss: 1.0480 - val_acc: 0.5098\n",
            "Epoch 602/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.0620 - acc: 0.4861 - val_loss: 1.0916 - val_acc: 0.5229\n",
            "Epoch 603/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.0789 - acc: 0.4975 - val_loss: 1.1517 - val_acc: 0.4967\n",
            "Epoch 604/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.0730 - acc: 0.4975 - val_loss: 1.1441 - val_acc: 0.4967\n",
            "Epoch 605/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0723 - acc: 0.5090 - val_loss: 1.0795 - val_acc: 0.5163\n",
            "Epoch 606/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.0718 - acc: 0.4894 - val_loss: 1.0522 - val_acc: 0.5098\n",
            "Epoch 607/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.0727 - acc: 0.5057 - val_loss: 1.0442 - val_acc: 0.5359\n",
            "Epoch 608/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0789 - acc: 0.4746 - val_loss: 1.0488 - val_acc: 0.5163\n",
            "Epoch 609/1000\n",
            "611/611 [==============================] - 0s 373us/sample - loss: 1.0678 - acc: 0.4746 - val_loss: 1.0521 - val_acc: 0.5098\n",
            "Epoch 610/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0710 - acc: 0.5090 - val_loss: 1.0469 - val_acc: 0.5294\n",
            "Epoch 611/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0572 - acc: 0.4992 - val_loss: 1.0903 - val_acc: 0.5098\n",
            "Epoch 612/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0578 - acc: 0.5057 - val_loss: 1.0445 - val_acc: 0.5163\n",
            "Epoch 613/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0601 - acc: 0.5106 - val_loss: 1.0873 - val_acc: 0.5163\n",
            "Epoch 614/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0662 - acc: 0.4959 - val_loss: 1.0552 - val_acc: 0.5163\n",
            "Epoch 615/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0631 - acc: 0.5057 - val_loss: 1.0433 - val_acc: 0.5163\n",
            "Epoch 616/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0674 - acc: 0.4828 - val_loss: 1.0539 - val_acc: 0.5229\n",
            "Epoch 617/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0797 - acc: 0.5025 - val_loss: 1.0519 - val_acc: 0.5098\n",
            "Epoch 618/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0747 - acc: 0.4795 - val_loss: 1.0419 - val_acc: 0.5229\n",
            "Epoch 619/1000\n",
            "611/611 [==============================] - 0s 438us/sample - loss: 1.0685 - acc: 0.4795 - val_loss: 1.0427 - val_acc: 0.5294\n",
            "Epoch 620/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0748 - acc: 0.5057 - val_loss: 1.0747 - val_acc: 0.5163\n",
            "Epoch 621/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0796 - acc: 0.4910 - val_loss: 1.0496 - val_acc: 0.5229\n",
            "Epoch 622/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0785 - acc: 0.5155 - val_loss: 1.0466 - val_acc: 0.5229\n",
            "Epoch 623/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0530 - acc: 0.5025 - val_loss: 1.0410 - val_acc: 0.5163\n",
            "Epoch 624/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0657 - acc: 0.4943 - val_loss: 1.0876 - val_acc: 0.5229\n",
            "Epoch 625/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0592 - acc: 0.4845 - val_loss: 1.0429 - val_acc: 0.5229\n",
            "Epoch 626/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0676 - acc: 0.5041 - val_loss: 1.0797 - val_acc: 0.5098\n",
            "Epoch 627/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0566 - acc: 0.5074 - val_loss: 1.0415 - val_acc: 0.5359\n",
            "Epoch 628/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.0562 - acc: 0.5172 - val_loss: 1.0942 - val_acc: 0.5229\n",
            "Epoch 629/1000\n",
            "611/611 [==============================] - 0s 379us/sample - loss: 1.0682 - acc: 0.5025 - val_loss: 1.0401 - val_acc: 0.5556\n",
            "Epoch 630/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0707 - acc: 0.4812 - val_loss: 1.0572 - val_acc: 0.5294\n",
            "Epoch 631/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0639 - acc: 0.5057 - val_loss: 1.0386 - val_acc: 0.5359\n",
            "Epoch 632/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0738 - acc: 0.5008 - val_loss: 1.0908 - val_acc: 0.5229\n",
            "Epoch 633/1000\n",
            "611/611 [==============================] - 0s 372us/sample - loss: 1.0665 - acc: 0.5041 - val_loss: 1.0517 - val_acc: 0.5294\n",
            "Epoch 634/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0745 - acc: 0.5041 - val_loss: 1.1125 - val_acc: 0.5033\n",
            "Epoch 635/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0599 - acc: 0.5090 - val_loss: 1.0495 - val_acc: 0.5294\n",
            "Epoch 636/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0634 - acc: 0.4812 - val_loss: 1.0400 - val_acc: 0.5359\n",
            "Epoch 637/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0556 - acc: 0.4943 - val_loss: 1.0855 - val_acc: 0.5033\n",
            "Epoch 638/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0494 - acc: 0.5221 - val_loss: 1.1029 - val_acc: 0.5098\n",
            "Epoch 639/1000\n",
            "611/611 [==============================] - 0s 364us/sample - loss: 1.0576 - acc: 0.5155 - val_loss: 1.0441 - val_acc: 0.5425\n",
            "Epoch 640/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0477 - acc: 0.4959 - val_loss: 1.0407 - val_acc: 0.5359\n",
            "Epoch 641/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.0710 - acc: 0.4992 - val_loss: 1.0385 - val_acc: 0.5359\n",
            "Epoch 642/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0795 - acc: 0.5155 - val_loss: 1.0567 - val_acc: 0.5098\n",
            "Epoch 643/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0594 - acc: 0.5123 - val_loss: 1.0401 - val_acc: 0.5425\n",
            "Epoch 644/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.0549 - acc: 0.4992 - val_loss: 1.0394 - val_acc: 0.5556\n",
            "Epoch 645/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.0532 - acc: 0.5172 - val_loss: 1.1860 - val_acc: 0.4902\n",
            "Epoch 646/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0531 - acc: 0.5123 - val_loss: 1.0506 - val_acc: 0.5229\n",
            "Epoch 647/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0776 - acc: 0.4959 - val_loss: 1.0466 - val_acc: 0.5229\n",
            "Epoch 648/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0569 - acc: 0.5254 - val_loss: 1.0962 - val_acc: 0.5098\n",
            "Epoch 649/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0689 - acc: 0.5172 - val_loss: 1.0435 - val_acc: 0.5425\n",
            "Epoch 650/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0834 - acc: 0.4877 - val_loss: 1.0528 - val_acc: 0.5229\n",
            "Epoch 651/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0504 - acc: 0.5155 - val_loss: 1.0403 - val_acc: 0.5359\n",
            "Epoch 652/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.0494 - acc: 0.5139 - val_loss: 1.0722 - val_acc: 0.5163\n",
            "Epoch 653/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 1.0812 - acc: 0.5074 - val_loss: 1.0435 - val_acc: 0.5425\n",
            "Epoch 654/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0592 - acc: 0.5041 - val_loss: 1.0601 - val_acc: 0.5229\n",
            "Epoch 655/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0393 - acc: 0.5106 - val_loss: 1.0399 - val_acc: 0.5425\n",
            "Epoch 656/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0545 - acc: 0.5041 - val_loss: 1.0348 - val_acc: 0.5425\n",
            "Epoch 657/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0543 - acc: 0.4975 - val_loss: 1.0392 - val_acc: 0.5425\n",
            "Epoch 658/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0506 - acc: 0.5057 - val_loss: 1.0794 - val_acc: 0.5098\n",
            "Epoch 659/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0683 - acc: 0.5008 - val_loss: 1.0341 - val_acc: 0.5425\n",
            "Epoch 660/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0769 - acc: 0.4959 - val_loss: 1.0364 - val_acc: 0.5556\n",
            "Epoch 661/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0520 - acc: 0.4959 - val_loss: 1.0527 - val_acc: 0.5163\n",
            "Epoch 662/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0709 - acc: 0.4975 - val_loss: 1.0337 - val_acc: 0.5294\n",
            "Epoch 663/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.0827 - acc: 0.4599 - val_loss: 1.0371 - val_acc: 0.5425\n",
            "Epoch 664/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.0726 - acc: 0.4992 - val_loss: 1.0334 - val_acc: 0.5490\n",
            "Epoch 665/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0563 - acc: 0.5205 - val_loss: 1.0500 - val_acc: 0.5163\n",
            "Epoch 666/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0468 - acc: 0.5090 - val_loss: 1.0454 - val_acc: 0.5229\n",
            "Epoch 667/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 1.0456 - acc: 0.5008 - val_loss: 1.0433 - val_acc: 0.5229\n",
            "Epoch 668/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.0462 - acc: 0.4943 - val_loss: 1.0354 - val_acc: 0.5556\n",
            "Epoch 669/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0633 - acc: 0.4795 - val_loss: 1.0568 - val_acc: 0.5098\n",
            "Epoch 670/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0444 - acc: 0.5106 - val_loss: 1.0361 - val_acc: 0.5556\n",
            "Epoch 671/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.0649 - acc: 0.4845 - val_loss: 1.0348 - val_acc: 0.5425\n",
            "Epoch 672/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0483 - acc: 0.5008 - val_loss: 1.0635 - val_acc: 0.5098\n",
            "Epoch 673/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0461 - acc: 0.5025 - val_loss: 1.0387 - val_acc: 0.5490\n",
            "Epoch 674/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0618 - acc: 0.5025 - val_loss: 1.0387 - val_acc: 0.5294\n",
            "Epoch 675/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0591 - acc: 0.4975 - val_loss: 1.0683 - val_acc: 0.5098\n",
            "Epoch 676/1000\n",
            "611/611 [==============================] - 0s 366us/sample - loss: 1.0639 - acc: 0.4877 - val_loss: 1.0424 - val_acc: 0.5229\n",
            "Epoch 677/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0529 - acc: 0.5319 - val_loss: 1.0743 - val_acc: 0.5098\n",
            "Epoch 678/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0361 - acc: 0.5336 - val_loss: 1.0373 - val_acc: 0.5425\n",
            "Epoch 679/1000\n",
            "611/611 [==============================] - 0s 364us/sample - loss: 1.0618 - acc: 0.5074 - val_loss: 1.0773 - val_acc: 0.5163\n",
            "Epoch 680/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0701 - acc: 0.4894 - val_loss: 1.0352 - val_acc: 0.5490\n",
            "Epoch 681/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0498 - acc: 0.5172 - val_loss: 1.0440 - val_acc: 0.5229\n",
            "Epoch 682/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0441 - acc: 0.5319 - val_loss: 1.0411 - val_acc: 0.5294\n",
            "Epoch 683/1000\n",
            "611/611 [==============================] - 0s 361us/sample - loss: 1.0427 - acc: 0.5237 - val_loss: 1.0469 - val_acc: 0.5163\n",
            "Epoch 684/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0554 - acc: 0.5090 - val_loss: 1.0291 - val_acc: 0.5425\n",
            "Epoch 685/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0556 - acc: 0.5041 - val_loss: 1.0318 - val_acc: 0.5490\n",
            "Epoch 686/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0531 - acc: 0.4926 - val_loss: 1.0450 - val_acc: 0.5359\n",
            "Epoch 687/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.0602 - acc: 0.4877 - val_loss: 1.0394 - val_acc: 0.5229\n",
            "Epoch 688/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0564 - acc: 0.5237 - val_loss: 1.0608 - val_acc: 0.5098\n",
            "Epoch 689/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0226 - acc: 0.5188 - val_loss: 1.0749 - val_acc: 0.5098\n",
            "Epoch 690/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0450 - acc: 0.5155 - val_loss: 1.0279 - val_acc: 0.5556\n",
            "Epoch 691/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.0616 - acc: 0.5123 - val_loss: 1.0275 - val_acc: 0.5490\n",
            "Epoch 692/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.0582 - acc: 0.4926 - val_loss: 1.0519 - val_acc: 0.5163\n",
            "Epoch 693/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0429 - acc: 0.5205 - val_loss: 1.1417 - val_acc: 0.5098\n",
            "Epoch 694/1000\n",
            "611/611 [==============================] - 0s 391us/sample - loss: 1.0611 - acc: 0.4943 - val_loss: 1.0300 - val_acc: 0.5359\n",
            "Epoch 695/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0578 - acc: 0.5237 - val_loss: 1.0247 - val_acc: 0.5425\n",
            "Epoch 696/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0584 - acc: 0.5172 - val_loss: 1.0247 - val_acc: 0.5425\n",
            "Epoch 697/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0536 - acc: 0.5106 - val_loss: 1.0479 - val_acc: 0.5163\n",
            "Epoch 698/1000\n",
            "611/611 [==============================] - 0s 400us/sample - loss: 1.0510 - acc: 0.5123 - val_loss: 1.0260 - val_acc: 0.5556\n",
            "Epoch 699/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0397 - acc: 0.5401 - val_loss: 1.0257 - val_acc: 0.5490\n",
            "Epoch 700/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0532 - acc: 0.5090 - val_loss: 1.0716 - val_acc: 0.5163\n",
            "Epoch 701/1000\n",
            "611/611 [==============================] - 0s 383us/sample - loss: 1.0399 - acc: 0.5106 - val_loss: 1.0249 - val_acc: 0.5556\n",
            "Epoch 702/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0417 - acc: 0.5270 - val_loss: 1.0252 - val_acc: 0.5556\n",
            "Epoch 703/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0514 - acc: 0.4975 - val_loss: 1.0546 - val_acc: 0.5229\n",
            "Epoch 704/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.0455 - acc: 0.5172 - val_loss: 1.0258 - val_acc: 0.5490\n",
            "Epoch 705/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0596 - acc: 0.5025 - val_loss: 1.0247 - val_acc: 0.5490\n",
            "Epoch 706/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0654 - acc: 0.4779 - val_loss: 1.0248 - val_acc: 0.5490\n",
            "Epoch 707/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.0404 - acc: 0.5057 - val_loss: 1.0481 - val_acc: 0.5294\n",
            "Epoch 708/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0536 - acc: 0.4926 - val_loss: 1.0257 - val_acc: 0.5490\n",
            "Epoch 709/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0387 - acc: 0.5106 - val_loss: 1.0233 - val_acc: 0.5425\n",
            "Epoch 710/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0672 - acc: 0.4795 - val_loss: 1.0960 - val_acc: 0.5229\n",
            "Epoch 711/1000\n",
            "611/611 [==============================] - 0s 364us/sample - loss: 1.0562 - acc: 0.4992 - val_loss: 1.0334 - val_acc: 0.5294\n",
            "Epoch 712/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0486 - acc: 0.5123 - val_loss: 1.0434 - val_acc: 0.5294\n",
            "Epoch 713/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0506 - acc: 0.5074 - val_loss: 1.0235 - val_acc: 0.5556\n",
            "Epoch 714/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0537 - acc: 0.4861 - val_loss: 1.0273 - val_acc: 0.5490\n",
            "Epoch 715/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.0529 - acc: 0.4992 - val_loss: 1.0854 - val_acc: 0.5359\n",
            "Epoch 716/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.0515 - acc: 0.5221 - val_loss: 1.0234 - val_acc: 0.5490\n",
            "Epoch 717/1000\n",
            "611/611 [==============================] - 0s 375us/sample - loss: 1.0551 - acc: 0.4992 - val_loss: 1.0375 - val_acc: 0.5425\n",
            "Epoch 718/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.0373 - acc: 0.5172 - val_loss: 1.0292 - val_acc: 0.5490\n",
            "Epoch 719/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.0495 - acc: 0.5106 - val_loss: 1.0635 - val_acc: 0.5229\n",
            "Epoch 720/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.0443 - acc: 0.5319 - val_loss: 1.0310 - val_acc: 0.5294\n",
            "Epoch 721/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0478 - acc: 0.5090 - val_loss: 1.0237 - val_acc: 0.5490\n",
            "Epoch 722/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.0338 - acc: 0.5205 - val_loss: 1.0212 - val_acc: 0.5425\n",
            "Epoch 723/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0335 - acc: 0.5221 - val_loss: 1.0478 - val_acc: 0.5229\n",
            "Epoch 724/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0243 - acc: 0.5286 - val_loss: 1.0227 - val_acc: 0.5425\n",
            "Epoch 725/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.0372 - acc: 0.5057 - val_loss: 1.0503 - val_acc: 0.5294\n",
            "Epoch 726/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0348 - acc: 0.5401 - val_loss: 1.0241 - val_acc: 0.5490\n",
            "Epoch 727/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.0468 - acc: 0.5319 - val_loss: 1.0283 - val_acc: 0.5359\n",
            "Epoch 728/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 1.0250 - acc: 0.5254 - val_loss: 1.0197 - val_acc: 0.5556\n",
            "Epoch 729/1000\n",
            "611/611 [==============================] - 0s 363us/sample - loss: 1.0488 - acc: 0.4779 - val_loss: 1.0199 - val_acc: 0.5359\n",
            "Epoch 730/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0566 - acc: 0.4975 - val_loss: 1.0540 - val_acc: 0.5294\n",
            "Epoch 731/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0639 - acc: 0.4943 - val_loss: 1.0225 - val_acc: 0.5490\n",
            "Epoch 732/1000\n",
            "611/611 [==============================] - 0s 379us/sample - loss: 1.0473 - acc: 0.5155 - val_loss: 1.1409 - val_acc: 0.5033\n",
            "Epoch 733/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0573 - acc: 0.5155 - val_loss: 1.0272 - val_acc: 0.5490\n",
            "Epoch 734/1000\n",
            "611/611 [==============================] - 0s 359us/sample - loss: 1.0453 - acc: 0.5188 - val_loss: 1.0216 - val_acc: 0.5817\n",
            "Epoch 735/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0420 - acc: 0.4975 - val_loss: 1.0196 - val_acc: 0.5556\n",
            "Epoch 736/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0316 - acc: 0.5188 - val_loss: 1.1092 - val_acc: 0.5163\n",
            "Epoch 737/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0538 - acc: 0.4910 - val_loss: 1.0279 - val_acc: 0.5425\n",
            "Epoch 738/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0430 - acc: 0.5188 - val_loss: 1.0547 - val_acc: 0.5229\n",
            "Epoch 739/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.0368 - acc: 0.5434 - val_loss: 1.0310 - val_acc: 0.5359\n",
            "Epoch 740/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0476 - acc: 0.5139 - val_loss: 1.0379 - val_acc: 0.5359\n",
            "Epoch 741/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0325 - acc: 0.5286 - val_loss: 1.0279 - val_acc: 0.5490\n",
            "Epoch 742/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0358 - acc: 0.5123 - val_loss: 1.0190 - val_acc: 0.5556\n",
            "Epoch 743/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0393 - acc: 0.5188 - val_loss: 1.0285 - val_acc: 0.5163\n",
            "Epoch 744/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0253 - acc: 0.5074 - val_loss: 1.0185 - val_acc: 0.5556\n",
            "Epoch 745/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0466 - acc: 0.5025 - val_loss: 1.0413 - val_acc: 0.5359\n",
            "Epoch 746/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 1.0477 - acc: 0.5106 - val_loss: 1.0292 - val_acc: 0.5425\n",
            "Epoch 747/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0389 - acc: 0.5319 - val_loss: 1.0197 - val_acc: 0.5490\n",
            "Epoch 748/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.0238 - acc: 0.5123 - val_loss: 1.0239 - val_acc: 0.5556\n",
            "Epoch 749/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0548 - acc: 0.5139 - val_loss: 1.0191 - val_acc: 0.5490\n",
            "Epoch 750/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0192 - acc: 0.5123 - val_loss: 1.0276 - val_acc: 0.5490\n",
            "Epoch 751/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0529 - acc: 0.5188 - val_loss: 1.0163 - val_acc: 0.5556\n",
            "Epoch 752/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0407 - acc: 0.4943 - val_loss: 1.0195 - val_acc: 0.5490\n",
            "Epoch 753/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0330 - acc: 0.5221 - val_loss: 1.0168 - val_acc: 0.5621\n",
            "Epoch 754/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0171 - acc: 0.5336 - val_loss: 1.0131 - val_acc: 0.5556\n",
            "Epoch 755/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0468 - acc: 0.5008 - val_loss: 1.0196 - val_acc: 0.5556\n",
            "Epoch 756/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0540 - acc: 0.4926 - val_loss: 1.0627 - val_acc: 0.5163\n",
            "Epoch 757/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0299 - acc: 0.5221 - val_loss: 1.0253 - val_acc: 0.5490\n",
            "Epoch 758/1000\n",
            "611/611 [==============================] - 0s 388us/sample - loss: 1.0290 - acc: 0.5565 - val_loss: 1.0178 - val_acc: 0.5556\n",
            "Epoch 759/1000\n",
            "611/611 [==============================] - 0s 382us/sample - loss: 1.0379 - acc: 0.5090 - val_loss: 1.0166 - val_acc: 0.5490\n",
            "Epoch 760/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 1.0204 - acc: 0.5270 - val_loss: 1.0122 - val_acc: 0.5556\n",
            "Epoch 761/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0385 - acc: 0.5025 - val_loss: 1.0138 - val_acc: 0.5621\n",
            "Epoch 762/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0336 - acc: 0.5025 - val_loss: 1.0182 - val_acc: 0.5294\n",
            "Epoch 763/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0570 - acc: 0.5008 - val_loss: 1.0334 - val_acc: 0.5294\n",
            "Epoch 764/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0403 - acc: 0.5123 - val_loss: 1.0174 - val_acc: 0.5686\n",
            "Epoch 765/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0442 - acc: 0.5254 - val_loss: 1.0600 - val_acc: 0.5163\n",
            "Epoch 766/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0334 - acc: 0.5123 - val_loss: 1.0159 - val_acc: 0.5621\n",
            "Epoch 767/1000\n",
            "611/611 [==============================] - 0s 379us/sample - loss: 1.0279 - acc: 0.5417 - val_loss: 1.0935 - val_acc: 0.5294\n",
            "Epoch 768/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.0191 - acc: 0.5188 - val_loss: 1.0489 - val_acc: 0.5229\n",
            "Epoch 769/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0287 - acc: 0.5139 - val_loss: 1.0831 - val_acc: 0.5229\n",
            "Epoch 770/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 1.0291 - acc: 0.5090 - val_loss: 1.0665 - val_acc: 0.5163\n",
            "Epoch 771/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0213 - acc: 0.5286 - val_loss: 1.0490 - val_acc: 0.5294\n",
            "Epoch 772/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0225 - acc: 0.5221 - val_loss: 1.0105 - val_acc: 0.5621\n",
            "Epoch 773/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0262 - acc: 0.5155 - val_loss: 1.0127 - val_acc: 0.5490\n",
            "Epoch 774/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0417 - acc: 0.4992 - val_loss: 1.0112 - val_acc: 0.5621\n",
            "Epoch 775/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0331 - acc: 0.4992 - val_loss: 1.0232 - val_acc: 0.5425\n",
            "Epoch 776/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0134 - acc: 0.5237 - val_loss: 1.0196 - val_acc: 0.5621\n",
            "Epoch 777/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0350 - acc: 0.5270 - val_loss: 1.0119 - val_acc: 0.5621\n",
            "Epoch 778/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0352 - acc: 0.5221 - val_loss: 1.0130 - val_acc: 0.5425\n",
            "Epoch 779/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0238 - acc: 0.5270 - val_loss: 1.0164 - val_acc: 0.5490\n",
            "Epoch 780/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0419 - acc: 0.5106 - val_loss: 1.0214 - val_acc: 0.5556\n",
            "Epoch 781/1000\n",
            "611/611 [==============================] - 0s 373us/sample - loss: 1.0177 - acc: 0.5319 - val_loss: 1.0164 - val_acc: 0.5556\n",
            "Epoch 782/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 1.0343 - acc: 0.5221 - val_loss: 1.0092 - val_acc: 0.5621\n",
            "Epoch 783/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0174 - acc: 0.5368 - val_loss: 1.0090 - val_acc: 0.5686\n",
            "Epoch 784/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0263 - acc: 0.5319 - val_loss: 1.1165 - val_acc: 0.5229\n",
            "Epoch 785/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0347 - acc: 0.5303 - val_loss: 1.1097 - val_acc: 0.5229\n",
            "Epoch 786/1000\n",
            "611/611 [==============================] - 0s 362us/sample - loss: 1.0246 - acc: 0.5123 - val_loss: 1.0066 - val_acc: 0.5686\n",
            "Epoch 787/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.0215 - acc: 0.5434 - val_loss: 1.0069 - val_acc: 0.5621\n",
            "Epoch 788/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.0233 - acc: 0.5106 - val_loss: 1.0333 - val_acc: 0.5425\n",
            "Epoch 789/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0212 - acc: 0.5270 - val_loss: 1.0596 - val_acc: 0.5229\n",
            "Epoch 790/1000\n",
            "611/611 [==============================] - 0s 369us/sample - loss: 1.0394 - acc: 0.5074 - val_loss: 1.0379 - val_acc: 0.5294\n",
            "Epoch 791/1000\n",
            "611/611 [==============================] - 0s 376us/sample - loss: 1.0293 - acc: 0.5319 - val_loss: 1.0353 - val_acc: 0.5294\n",
            "Epoch 792/1000\n",
            "611/611 [==============================] - 0s 380us/sample - loss: 1.0414 - acc: 0.5008 - val_loss: 1.0098 - val_acc: 0.5686\n",
            "Epoch 793/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0434 - acc: 0.5057 - val_loss: 1.0062 - val_acc: 0.5621\n",
            "Epoch 794/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0372 - acc: 0.4992 - val_loss: 1.1084 - val_acc: 0.5229\n",
            "Epoch 795/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.0367 - acc: 0.4992 - val_loss: 1.0095 - val_acc: 0.5556\n",
            "Epoch 796/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0114 - acc: 0.5270 - val_loss: 1.0087 - val_acc: 0.5621\n",
            "Epoch 797/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.0045 - acc: 0.5286 - val_loss: 1.0091 - val_acc: 0.5621\n",
            "Epoch 798/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0296 - acc: 0.5368 - val_loss: 1.0300 - val_acc: 0.5359\n",
            "Epoch 799/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0055 - acc: 0.5466 - val_loss: 1.0183 - val_acc: 0.5556\n",
            "Epoch 800/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 1.0360 - acc: 0.5074 - val_loss: 1.0071 - val_acc: 0.5621\n",
            "Epoch 801/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0338 - acc: 0.5188 - val_loss: 1.0188 - val_acc: 0.5359\n",
            "Epoch 802/1000\n",
            "611/611 [==============================] - 0s 375us/sample - loss: 1.0353 - acc: 0.5090 - val_loss: 1.0235 - val_acc: 0.5490\n",
            "Epoch 803/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0254 - acc: 0.5155 - val_loss: 1.0049 - val_acc: 0.5621\n",
            "Epoch 804/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0297 - acc: 0.5368 - val_loss: 1.0061 - val_acc: 0.5621\n",
            "Epoch 805/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.0247 - acc: 0.4959 - val_loss: 1.0535 - val_acc: 0.5229\n",
            "Epoch 806/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 1.0385 - acc: 0.5221 - val_loss: 1.0053 - val_acc: 0.5621\n",
            "Epoch 807/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0194 - acc: 0.5237 - val_loss: 1.0052 - val_acc: 0.5686\n",
            "Epoch 808/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0134 - acc: 0.5041 - val_loss: 1.0061 - val_acc: 0.5686\n",
            "Epoch 809/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0283 - acc: 0.5205 - val_loss: 1.0318 - val_acc: 0.5621\n",
            "Epoch 810/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 0.9966 - acc: 0.5663 - val_loss: 1.0025 - val_acc: 0.5556\n",
            "Epoch 811/1000\n",
            "611/611 [==============================] - 0s 383us/sample - loss: 1.0188 - acc: 0.5205 - val_loss: 1.0268 - val_acc: 0.5359\n",
            "Epoch 812/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.0437 - acc: 0.5188 - val_loss: 1.0471 - val_acc: 0.5294\n",
            "Epoch 813/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0223 - acc: 0.5254 - val_loss: 1.0390 - val_acc: 0.5294\n",
            "Epoch 814/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.0219 - acc: 0.5270 - val_loss: 1.0064 - val_acc: 0.5752\n",
            "Epoch 815/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0251 - acc: 0.5123 - val_loss: 1.0811 - val_acc: 0.5098\n",
            "Epoch 816/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 1.0444 - acc: 0.5172 - val_loss: 1.0060 - val_acc: 0.5621\n",
            "Epoch 817/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 1.0279 - acc: 0.5385 - val_loss: 1.0142 - val_acc: 0.5621\n",
            "Epoch 818/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0116 - acc: 0.5352 - val_loss: 1.0068 - val_acc: 0.5490\n",
            "Epoch 819/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0205 - acc: 0.5385 - val_loss: 1.0195 - val_acc: 0.5425\n",
            "Epoch 820/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0039 - acc: 0.5483 - val_loss: 1.0312 - val_acc: 0.5425\n",
            "Epoch 821/1000\n",
            "611/611 [==============================] - 0s 384us/sample - loss: 1.0246 - acc: 0.5352 - val_loss: 1.0340 - val_acc: 0.5359\n",
            "Epoch 822/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0298 - acc: 0.5385 - val_loss: 1.0270 - val_acc: 0.5425\n",
            "Epoch 823/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0287 - acc: 0.5139 - val_loss: 1.0415 - val_acc: 0.5359\n",
            "Epoch 824/1000\n",
            "611/611 [==============================] - 0s 347us/sample - loss: 1.0208 - acc: 0.5041 - val_loss: 1.0058 - val_acc: 0.5556\n",
            "Epoch 825/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0338 - acc: 0.5188 - val_loss: 1.0279 - val_acc: 0.5556\n",
            "Epoch 826/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 1.0353 - acc: 0.5025 - val_loss: 1.0192 - val_acc: 0.5425\n",
            "Epoch 827/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0115 - acc: 0.5352 - val_loss: 1.0039 - val_acc: 0.5556\n",
            "Epoch 828/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0315 - acc: 0.5188 - val_loss: 1.0127 - val_acc: 0.5556\n",
            "Epoch 829/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0116 - acc: 0.5319 - val_loss: 1.0554 - val_acc: 0.5294\n",
            "Epoch 830/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0089 - acc: 0.5074 - val_loss: 1.0160 - val_acc: 0.5556\n",
            "Epoch 831/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0116 - acc: 0.5254 - val_loss: 1.0072 - val_acc: 0.5621\n",
            "Epoch 832/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0189 - acc: 0.5319 - val_loss: 1.1175 - val_acc: 0.5229\n",
            "Epoch 833/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0204 - acc: 0.5237 - val_loss: 1.0096 - val_acc: 0.5556\n",
            "Epoch 834/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0317 - acc: 0.5254 - val_loss: 1.0051 - val_acc: 0.5556\n",
            "Epoch 835/1000\n",
            "611/611 [==============================] - 0s 378us/sample - loss: 1.0110 - acc: 0.5139 - val_loss: 1.0011 - val_acc: 0.5621\n",
            "Epoch 836/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0107 - acc: 0.5319 - val_loss: 1.0011 - val_acc: 0.5686\n",
            "Epoch 837/1000\n",
            "611/611 [==============================] - 0s 357us/sample - loss: 1.0035 - acc: 0.5303 - val_loss: 1.1321 - val_acc: 0.5229\n",
            "Epoch 838/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0125 - acc: 0.5483 - val_loss: 1.0011 - val_acc: 0.5686\n",
            "Epoch 839/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0205 - acc: 0.5041 - val_loss: 1.0201 - val_acc: 0.5556\n",
            "Epoch 840/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0112 - acc: 0.5025 - val_loss: 1.0060 - val_acc: 0.5621\n",
            "Epoch 841/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0210 - acc: 0.5041 - val_loss: 1.0050 - val_acc: 0.5490\n",
            "Epoch 842/1000\n",
            "611/611 [==============================] - 0s 368us/sample - loss: 1.0352 - acc: 0.5254 - val_loss: 1.0043 - val_acc: 0.5621\n",
            "Epoch 843/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0286 - acc: 0.5155 - val_loss: 1.0253 - val_acc: 0.5425\n",
            "Epoch 844/1000\n",
            "611/611 [==============================] - 0s 310us/sample - loss: 1.0200 - acc: 0.5188 - val_loss: 1.0278 - val_acc: 0.5425\n",
            "Epoch 845/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0260 - acc: 0.5254 - val_loss: 1.0044 - val_acc: 0.5752\n",
            "Epoch 846/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0122 - acc: 0.5254 - val_loss: 1.0096 - val_acc: 0.5556\n",
            "Epoch 847/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0254 - acc: 0.5123 - val_loss: 1.0454 - val_acc: 0.5359\n",
            "Epoch 848/1000\n",
            "611/611 [==============================] - 0s 337us/sample - loss: 1.0220 - acc: 0.5499 - val_loss: 1.0042 - val_acc: 0.5621\n",
            "Epoch 849/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0184 - acc: 0.5385 - val_loss: 1.0308 - val_acc: 0.5490\n",
            "Epoch 850/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0163 - acc: 0.5254 - val_loss: 1.0211 - val_acc: 0.5359\n",
            "Epoch 851/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.0127 - acc: 0.5237 - val_loss: 1.0176 - val_acc: 0.5490\n",
            "Epoch 852/1000\n",
            "611/611 [==============================] - 0s 332us/sample - loss: 1.0065 - acc: 0.5123 - val_loss: 0.9986 - val_acc: 0.5817\n",
            "Epoch 853/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0083 - acc: 0.5401 - val_loss: 1.0060 - val_acc: 0.5621\n",
            "Epoch 854/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0241 - acc: 0.5237 - val_loss: 1.0013 - val_acc: 0.5621\n",
            "Epoch 855/1000\n",
            "611/611 [==============================] - 0s 370us/sample - loss: 1.0136 - acc: 0.5499 - val_loss: 1.0044 - val_acc: 0.5621\n",
            "Epoch 856/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 0.9976 - acc: 0.5532 - val_loss: 0.9995 - val_acc: 0.5621\n",
            "Epoch 857/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 0.9931 - acc: 0.5696 - val_loss: 1.0035 - val_acc: 0.5490\n",
            "Epoch 858/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0093 - acc: 0.5336 - val_loss: 1.0405 - val_acc: 0.5425\n",
            "Epoch 859/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0038 - acc: 0.5548 - val_loss: 1.0672 - val_acc: 0.5163\n",
            "Epoch 860/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0198 - acc: 0.5254 - val_loss: 1.0017 - val_acc: 0.5686\n",
            "Epoch 861/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.0211 - acc: 0.5155 - val_loss: 0.9959 - val_acc: 0.5686\n",
            "Epoch 862/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 1.0067 - acc: 0.5139 - val_loss: 1.0778 - val_acc: 0.5229\n",
            "Epoch 863/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0084 - acc: 0.5385 - val_loss: 1.0072 - val_acc: 0.5490\n",
            "Epoch 864/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 1.0145 - acc: 0.5303 - val_loss: 1.0299 - val_acc: 0.5490\n",
            "Epoch 865/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0010 - acc: 0.5434 - val_loss: 0.9979 - val_acc: 0.5752\n",
            "Epoch 866/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0005 - acc: 0.5450 - val_loss: 1.0434 - val_acc: 0.5425\n",
            "Epoch 867/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 1.0122 - acc: 0.5139 - val_loss: 1.0207 - val_acc: 0.5490\n",
            "Epoch 868/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.0213 - acc: 0.5516 - val_loss: 0.9948 - val_acc: 0.5752\n",
            "Epoch 869/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 0.9786 - acc: 0.5516 - val_loss: 0.9984 - val_acc: 0.5621\n",
            "Epoch 870/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0124 - acc: 0.5254 - val_loss: 0.9922 - val_acc: 0.5752\n",
            "Epoch 871/1000\n",
            "611/611 [==============================] - 0s 341us/sample - loss: 1.0025 - acc: 0.5270 - val_loss: 1.0422 - val_acc: 0.5425\n",
            "Epoch 872/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0019 - acc: 0.5499 - val_loss: 1.0042 - val_acc: 0.5621\n",
            "Epoch 873/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 1.0044 - acc: 0.5401 - val_loss: 0.9975 - val_acc: 0.5752\n",
            "Epoch 874/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0065 - acc: 0.5368 - val_loss: 0.9993 - val_acc: 0.5621\n",
            "Epoch 875/1000\n",
            "611/611 [==============================] - 0s 338us/sample - loss: 0.9847 - acc: 0.5483 - val_loss: 0.9933 - val_acc: 0.5621\n",
            "Epoch 876/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 0.9981 - acc: 0.5548 - val_loss: 1.0850 - val_acc: 0.5163\n",
            "Epoch 877/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 1.0027 - acc: 0.5139 - val_loss: 1.0517 - val_acc: 0.5294\n",
            "Epoch 878/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9974 - acc: 0.5728 - val_loss: 0.9958 - val_acc: 0.5621\n",
            "Epoch 879/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 0.9918 - acc: 0.5696 - val_loss: 1.0143 - val_acc: 0.5556\n",
            "Epoch 880/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 1.0040 - acc: 0.5319 - val_loss: 0.9970 - val_acc: 0.5621\n",
            "Epoch 881/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.0150 - acc: 0.5270 - val_loss: 1.0302 - val_acc: 0.5490\n",
            "Epoch 882/1000\n",
            "611/611 [==============================] - 0s 376us/sample - loss: 1.0077 - acc: 0.5466 - val_loss: 1.0005 - val_acc: 0.5556\n",
            "Epoch 883/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 1.0051 - acc: 0.5336 - val_loss: 1.0191 - val_acc: 0.5490\n",
            "Epoch 884/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 1.0080 - acc: 0.5352 - val_loss: 0.9981 - val_acc: 0.5686\n",
            "Epoch 885/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.0037 - acc: 0.5499 - val_loss: 0.9903 - val_acc: 0.5686\n",
            "Epoch 886/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 0.9987 - acc: 0.5385 - val_loss: 0.9971 - val_acc: 0.5686\n",
            "Epoch 887/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 1.0039 - acc: 0.5466 - val_loss: 0.9899 - val_acc: 0.5882\n",
            "Epoch 888/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 1.0043 - acc: 0.5188 - val_loss: 1.0000 - val_acc: 0.5556\n",
            "Epoch 889/1000\n",
            "611/611 [==============================] - 0s 340us/sample - loss: 1.0102 - acc: 0.5237 - val_loss: 0.9948 - val_acc: 0.5752\n",
            "Epoch 890/1000\n",
            "611/611 [==============================] - 0s 352us/sample - loss: 1.0083 - acc: 0.5368 - val_loss: 0.9925 - val_acc: 0.5686\n",
            "Epoch 891/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 1.0066 - acc: 0.5188 - val_loss: 0.9890 - val_acc: 0.5752\n",
            "Epoch 892/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 0.9959 - acc: 0.5319 - val_loss: 0.9886 - val_acc: 0.5752\n",
            "Epoch 893/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 0.9955 - acc: 0.5188 - val_loss: 0.9871 - val_acc: 0.5686\n",
            "Epoch 894/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 1.0045 - acc: 0.5270 - val_loss: 1.0113 - val_acc: 0.5229\n",
            "Epoch 895/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 0.9970 - acc: 0.5450 - val_loss: 1.0212 - val_acc: 0.5425\n",
            "Epoch 896/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0151 - acc: 0.5401 - val_loss: 1.1343 - val_acc: 0.5163\n",
            "Epoch 897/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0232 - acc: 0.5254 - val_loss: 1.0034 - val_acc: 0.5556\n",
            "Epoch 898/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0103 - acc: 0.5237 - val_loss: 1.0168 - val_acc: 0.5490\n",
            "Epoch 899/1000\n",
            "611/611 [==============================] - 0s 376us/sample - loss: 1.0093 - acc: 0.5434 - val_loss: 0.9967 - val_acc: 0.5686\n",
            "Epoch 900/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 0.9924 - acc: 0.5172 - val_loss: 0.9973 - val_acc: 0.5490\n",
            "Epoch 901/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 1.0084 - acc: 0.5139 - val_loss: 1.0111 - val_acc: 0.5425\n",
            "Epoch 902/1000\n",
            "611/611 [==============================] - 0s 391us/sample - loss: 1.0144 - acc: 0.5270 - val_loss: 0.9920 - val_acc: 0.5752\n",
            "Epoch 903/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0061 - acc: 0.5483 - val_loss: 1.0035 - val_acc: 0.5556\n",
            "Epoch 904/1000\n",
            "611/611 [==============================] - 0s 381us/sample - loss: 1.0136 - acc: 0.5270 - val_loss: 0.9876 - val_acc: 0.5948\n",
            "Epoch 905/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 0.9975 - acc: 0.5303 - val_loss: 1.0289 - val_acc: 0.5490\n",
            "Epoch 906/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9941 - acc: 0.5597 - val_loss: 1.0117 - val_acc: 0.5490\n",
            "Epoch 907/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9930 - acc: 0.5483 - val_loss: 0.9887 - val_acc: 0.5752\n",
            "Epoch 908/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 1.0060 - acc: 0.5336 - val_loss: 1.0257 - val_acc: 0.5490\n",
            "Epoch 909/1000\n",
            "611/611 [==============================] - 0s 349us/sample - loss: 0.9998 - acc: 0.5352 - val_loss: 0.9964 - val_acc: 0.5556\n",
            "Epoch 910/1000\n",
            "611/611 [==============================] - 0s 317us/sample - loss: 0.9925 - acc: 0.5336 - val_loss: 0.9890 - val_acc: 0.5686\n",
            "Epoch 911/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 1.0062 - acc: 0.5336 - val_loss: 0.9888 - val_acc: 0.5686\n",
            "Epoch 912/1000\n",
            "611/611 [==============================] - 0s 372us/sample - loss: 0.9897 - acc: 0.5483 - val_loss: 0.9871 - val_acc: 0.5817\n",
            "Epoch 913/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 0.9833 - acc: 0.5499 - val_loss: 1.0812 - val_acc: 0.5229\n",
            "Epoch 914/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 1.0133 - acc: 0.5352 - val_loss: 0.9863 - val_acc: 0.5882\n",
            "Epoch 915/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 1.0011 - acc: 0.5352 - val_loss: 0.9880 - val_acc: 0.5686\n",
            "Epoch 916/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 0.9999 - acc: 0.5385 - val_loss: 1.0095 - val_acc: 0.5556\n",
            "Epoch 917/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 0.9924 - acc: 0.5286 - val_loss: 0.9924 - val_acc: 0.5752\n",
            "Epoch 918/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 0.9944 - acc: 0.5336 - val_loss: 0.9869 - val_acc: 0.5752\n",
            "Epoch 919/1000\n",
            "611/611 [==============================] - 0s 360us/sample - loss: 0.9838 - acc: 0.5434 - val_loss: 0.9888 - val_acc: 0.5686\n",
            "Epoch 920/1000\n",
            "611/611 [==============================] - 0s 314us/sample - loss: 1.0033 - acc: 0.5352 - val_loss: 0.9966 - val_acc: 0.5621\n",
            "Epoch 921/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 0.9970 - acc: 0.5499 - val_loss: 0.9849 - val_acc: 0.5686\n",
            "Epoch 922/1000\n",
            "611/611 [==============================] - 0s 319us/sample - loss: 0.9867 - acc: 0.5434 - val_loss: 1.0410 - val_acc: 0.5425\n",
            "Epoch 923/1000\n",
            "611/611 [==============================] - 0s 366us/sample - loss: 0.9906 - acc: 0.5336 - val_loss: 0.9910 - val_acc: 0.5686\n",
            "Epoch 924/1000\n",
            "611/611 [==============================] - 0s 339us/sample - loss: 1.0127 - acc: 0.5303 - val_loss: 0.9871 - val_acc: 0.5817\n",
            "Epoch 925/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 0.9846 - acc: 0.5270 - val_loss: 1.0148 - val_acc: 0.5490\n",
            "Epoch 926/1000\n",
            "611/611 [==============================] - 0s 377us/sample - loss: 1.0167 - acc: 0.5237 - val_loss: 0.9843 - val_acc: 0.5621\n",
            "Epoch 927/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 0.9900 - acc: 0.5434 - val_loss: 1.0012 - val_acc: 0.5490\n",
            "Epoch 928/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 0.9850 - acc: 0.5548 - val_loss: 1.0048 - val_acc: 0.5490\n",
            "Epoch 929/1000\n",
            "611/611 [==============================] - 0s 358us/sample - loss: 0.9828 - acc: 0.5417 - val_loss: 1.0219 - val_acc: 0.5425\n",
            "Epoch 930/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 0.9834 - acc: 0.5646 - val_loss: 0.9944 - val_acc: 0.5686\n",
            "Epoch 931/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 1.0069 - acc: 0.5303 - val_loss: 0.9881 - val_acc: 0.5882\n",
            "Epoch 932/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0185 - acc: 0.5466 - val_loss: 0.9878 - val_acc: 0.5752\n",
            "Epoch 933/1000\n",
            "611/611 [==============================] - 0s 403us/sample - loss: 1.0062 - acc: 0.5237 - val_loss: 0.9882 - val_acc: 0.5752\n",
            "Epoch 934/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 0.9904 - acc: 0.5270 - val_loss: 1.0489 - val_acc: 0.5359\n",
            "Epoch 935/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0003 - acc: 0.5254 - val_loss: 1.0672 - val_acc: 0.5359\n",
            "Epoch 936/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9866 - acc: 0.5532 - val_loss: 0.9907 - val_acc: 0.5686\n",
            "Epoch 937/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 1.0019 - acc: 0.5450 - val_loss: 0.9854 - val_acc: 0.5948\n",
            "Epoch 938/1000\n",
            "611/611 [==============================] - 0s 384us/sample - loss: 0.9948 - acc: 0.5434 - val_loss: 0.9909 - val_acc: 0.5752\n",
            "Epoch 939/1000\n",
            "611/611 [==============================] - 0s 333us/sample - loss: 0.9899 - acc: 0.5434 - val_loss: 0.9890 - val_acc: 0.5817\n",
            "Epoch 940/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 0.9806 - acc: 0.5303 - val_loss: 0.9905 - val_acc: 0.5752\n",
            "Epoch 941/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 0.9860 - acc: 0.5466 - val_loss: 0.9843 - val_acc: 0.5882\n",
            "Epoch 942/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9981 - acc: 0.5286 - val_loss: 0.9823 - val_acc: 0.5752\n",
            "Epoch 943/1000\n",
            "611/611 [==============================] - 0s 373us/sample - loss: 0.9961 - acc: 0.5303 - val_loss: 0.9837 - val_acc: 0.5752\n",
            "Epoch 944/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 0.9892 - acc: 0.5516 - val_loss: 0.9896 - val_acc: 0.5686\n",
            "Epoch 945/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0040 - acc: 0.5237 - val_loss: 0.9858 - val_acc: 0.5817\n",
            "Epoch 946/1000\n",
            "611/611 [==============================] - 0s 328us/sample - loss: 0.9748 - acc: 0.5352 - val_loss: 0.9875 - val_acc: 0.5948\n",
            "Epoch 947/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9912 - acc: 0.5336 - val_loss: 1.0836 - val_acc: 0.5294\n",
            "Epoch 948/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 0.9742 - acc: 0.5630 - val_loss: 1.0002 - val_acc: 0.5556\n",
            "Epoch 949/1000\n",
            "611/611 [==============================] - 0s 324us/sample - loss: 0.9882 - acc: 0.5417 - val_loss: 0.9851 - val_acc: 0.5948\n",
            "Epoch 950/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 0.9890 - acc: 0.5286 - val_loss: 0.9875 - val_acc: 0.5752\n",
            "Epoch 951/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 0.9921 - acc: 0.5368 - val_loss: 0.9824 - val_acc: 0.5817\n",
            "Epoch 952/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0043 - acc: 0.5270 - val_loss: 1.0095 - val_acc: 0.5490\n",
            "Epoch 953/1000\n",
            "611/611 [==============================] - 0s 365us/sample - loss: 0.9947 - acc: 0.5270 - val_loss: 0.9800 - val_acc: 0.5882\n",
            "Epoch 954/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 0.9885 - acc: 0.5434 - val_loss: 0.9865 - val_acc: 0.5817\n",
            "Epoch 955/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0018 - acc: 0.5401 - val_loss: 0.9906 - val_acc: 0.6078\n",
            "Epoch 956/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 1.0098 - acc: 0.5270 - val_loss: 0.9824 - val_acc: 0.5752\n",
            "Epoch 957/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 0.9851 - acc: 0.5139 - val_loss: 0.9826 - val_acc: 0.5948\n",
            "Epoch 958/1000\n",
            "611/611 [==============================] - 0s 350us/sample - loss: 1.0133 - acc: 0.5303 - val_loss: 1.0116 - val_acc: 0.5490\n",
            "Epoch 959/1000\n",
            "611/611 [==============================] - 0s 356us/sample - loss: 0.9943 - acc: 0.5532 - val_loss: 0.9784 - val_acc: 0.5882\n",
            "Epoch 960/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 0.9751 - acc: 0.5483 - val_loss: 0.9797 - val_acc: 0.5882\n",
            "Epoch 961/1000\n",
            "611/611 [==============================] - 0s 318us/sample - loss: 1.0003 - acc: 0.5286 - val_loss: 0.9910 - val_acc: 0.5686\n",
            "Epoch 962/1000\n",
            "611/611 [==============================] - 0s 353us/sample - loss: 0.9918 - acc: 0.5352 - val_loss: 0.9858 - val_acc: 0.5752\n",
            "Epoch 963/1000\n",
            "611/611 [==============================] - 0s 346us/sample - loss: 0.9800 - acc: 0.5385 - val_loss: 1.0150 - val_acc: 0.5425\n",
            "Epoch 964/1000\n",
            "611/611 [==============================] - 0s 313us/sample - loss: 1.0060 - acc: 0.5319 - val_loss: 0.9848 - val_acc: 0.6013\n",
            "Epoch 965/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 0.9810 - acc: 0.5499 - val_loss: 0.9937 - val_acc: 0.5686\n",
            "Epoch 966/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 0.9775 - acc: 0.5630 - val_loss: 0.9798 - val_acc: 0.5686\n",
            "Epoch 967/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 1.0043 - acc: 0.5336 - val_loss: 1.0044 - val_acc: 0.5425\n",
            "Epoch 968/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 0.9877 - acc: 0.5450 - val_loss: 1.0319 - val_acc: 0.5359\n",
            "Epoch 969/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 1.0149 - acc: 0.5434 - val_loss: 0.9866 - val_acc: 0.5686\n",
            "Epoch 970/1000\n",
            "611/611 [==============================] - 0s 344us/sample - loss: 0.9884 - acc: 0.5319 - val_loss: 0.9805 - val_acc: 0.5817\n",
            "Epoch 971/1000\n",
            "611/611 [==============================] - 0s 400us/sample - loss: 0.9771 - acc: 0.5417 - val_loss: 0.9796 - val_acc: 0.5817\n",
            "Epoch 972/1000\n",
            "611/611 [==============================] - 0s 355us/sample - loss: 0.9700 - acc: 0.5466 - val_loss: 0.9830 - val_acc: 0.5817\n",
            "Epoch 973/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 0.9872 - acc: 0.5450 - val_loss: 0.9908 - val_acc: 0.5621\n",
            "Epoch 974/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 0.9803 - acc: 0.5417 - val_loss: 0.9906 - val_acc: 0.5948\n",
            "Epoch 975/1000\n",
            "611/611 [==============================] - 0s 342us/sample - loss: 0.9935 - acc: 0.5319 - val_loss: 0.9799 - val_acc: 0.5817\n",
            "Epoch 976/1000\n",
            "611/611 [==============================] - 0s 326us/sample - loss: 0.9820 - acc: 0.5368 - val_loss: 1.0263 - val_acc: 0.5490\n",
            "Epoch 977/1000\n",
            "611/611 [==============================] - 0s 369us/sample - loss: 0.9826 - acc: 0.5385 - val_loss: 0.9770 - val_acc: 0.5948\n",
            "Epoch 978/1000\n",
            "611/611 [==============================] - 0s 354us/sample - loss: 1.0006 - acc: 0.5221 - val_loss: 0.9799 - val_acc: 0.5621\n",
            "Epoch 979/1000\n",
            "611/611 [==============================] - 0s 323us/sample - loss: 0.9705 - acc: 0.5516 - val_loss: 0.9754 - val_acc: 0.5882\n",
            "Epoch 980/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 0.9813 - acc: 0.5483 - val_loss: 0.9797 - val_acc: 0.5621\n",
            "Epoch 981/1000\n",
            "611/611 [==============================] - 0s 315us/sample - loss: 0.9882 - acc: 0.5565 - val_loss: 0.9986 - val_acc: 0.5621\n",
            "Epoch 982/1000\n",
            "611/611 [==============================] - 0s 345us/sample - loss: 0.9851 - acc: 0.5401 - val_loss: 0.9831 - val_acc: 0.5490\n",
            "Epoch 983/1000\n",
            "611/611 [==============================] - 0s 336us/sample - loss: 0.9679 - acc: 0.5450 - val_loss: 0.9829 - val_acc: 0.5817\n",
            "Epoch 984/1000\n",
            "611/611 [==============================] - 0s 348us/sample - loss: 0.9827 - acc: 0.5286 - val_loss: 0.9759 - val_acc: 0.6013\n",
            "Epoch 985/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0005 - acc: 0.5417 - val_loss: 0.9807 - val_acc: 0.5817\n",
            "Epoch 986/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 0.9927 - acc: 0.5499 - val_loss: 0.9811 - val_acc: 0.5817\n",
            "Epoch 987/1000\n",
            "611/611 [==============================] - 0s 334us/sample - loss: 0.9907 - acc: 0.5254 - val_loss: 0.9809 - val_acc: 0.5882\n",
            "Epoch 988/1000\n",
            "611/611 [==============================] - 0s 335us/sample - loss: 0.9956 - acc: 0.5581 - val_loss: 0.9884 - val_acc: 0.5686\n",
            "Epoch 989/1000\n",
            "611/611 [==============================] - 0s 327us/sample - loss: 1.0167 - acc: 0.5221 - val_loss: 1.0644 - val_acc: 0.5229\n",
            "Epoch 990/1000\n",
            "611/611 [==============================] - 0s 316us/sample - loss: 0.9887 - acc: 0.5532 - val_loss: 0.9952 - val_acc: 0.5621\n",
            "Epoch 991/1000\n",
            "611/611 [==============================] - 0s 331us/sample - loss: 0.9768 - acc: 0.5696 - val_loss: 0.9812 - val_acc: 0.5882\n",
            "Epoch 992/1000\n",
            "611/611 [==============================] - 0s 343us/sample - loss: 0.9871 - acc: 0.5630 - val_loss: 0.9766 - val_acc: 0.5752\n",
            "Epoch 993/1000\n",
            "611/611 [==============================] - 0s 330us/sample - loss: 0.9847 - acc: 0.5499 - val_loss: 0.9812 - val_acc: 0.5817\n",
            "Epoch 994/1000\n",
            "611/611 [==============================] - 0s 320us/sample - loss: 0.9837 - acc: 0.5401 - val_loss: 0.9884 - val_acc: 0.5752\n",
            "Epoch 995/1000\n",
            "611/611 [==============================] - 0s 321us/sample - loss: 0.9979 - acc: 0.5385 - val_loss: 1.0364 - val_acc: 0.5294\n",
            "Epoch 996/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 0.9867 - acc: 0.5319 - val_loss: 1.0104 - val_acc: 0.5359\n",
            "Epoch 997/1000\n",
            "611/611 [==============================] - 0s 351us/sample - loss: 0.9807 - acc: 0.5401 - val_loss: 0.9759 - val_acc: 0.5882\n",
            "Epoch 998/1000\n",
            "611/611 [==============================] - 0s 329us/sample - loss: 0.9752 - acc: 0.5319 - val_loss: 0.9849 - val_acc: 0.5752\n",
            "Epoch 999/1000\n",
            "611/611 [==============================] - 0s 322us/sample - loss: 0.9763 - acc: 0.5483 - val_loss: 0.9823 - val_acc: 0.5686\n",
            "Epoch 1000/1000\n",
            "611/611 [==============================] - 0s 325us/sample - loss: 0.9852 - acc: 0.5450 - val_loss: 1.0073 - val_acc: 0.5490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F5VUbbduWAZ",
        "colab_type": "code",
        "outputId": "0de770f3-c0da-4d13-d854-26ef9b8b52f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nURxRgVAURVEc+X82YBdeHmbDTgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-cjAk2JzFO0",
        "colab_type": "text"
      },
      "source": [
        "#Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25TUSa5_zJT7",
        "colab_type": "code",
        "outputId": "b154f740-6d4d-467f-ce91-36edd703c7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_name = 'Emotion_Voice_Detection_CNN_Model.h5'\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model2.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/Emotion_Voice_Detection_CNN_Model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qujVkT96zrRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#write model JSON\n",
        "import json\n",
        "model_json = model2.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp122lW60Boo",
        "colab_type": "text"
      },
      "source": [
        "#Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smcV2my2z_us",
        "colab_type": "code",
        "outputId": "2fcd0b13-dd12-4a0f-8b2b-db4132c250d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('/content/model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/saved_models/Emotion_Voice_Detection_CNN_Model.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', \n",
        "                     optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001, decay=1e-6), \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1371dc49a51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/saved_models/Emotion_Voice_Detection_CNN_Model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 147\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_configs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             layer = layer_module.deserialize(conf,\n\u001b[0;32m--> 301\u001b[0;31m                                              custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m                                         list(custom_objects.items())))\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/initializers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    494\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                                     printable_module_name='initializer')\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 140\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown initializer: GlorotUniform"
          ]
        }
      ]
    }
  ]
}